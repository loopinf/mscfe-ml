{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "5AxF11X9tHvo"
   },
   "source": [
    "\n",
    "## MACHINE LEARNING IN FINANCE\n",
    "MODULE 7 | LESSON 3\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "J4ceGgiItOf0"
   },
   "source": [
    "# **MODEL EVALUATION AND REGULARIZATION**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "MELzJ6aRtXsV"
   },
   "source": [
    "\n",
    "|  |  |\n",
    "|:---|:---|\n",
    "|**Reading Time** | 40 minutes |\n",
    "|**Prior Knowledge** | Introduction to hyperparameter tuning, loss functions  |\n",
    "|**Keywords** |simulated annealing  |\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "mg7hqOaYt6Be"
   },
   "source": [
    "*In the previous lesson, we applied grid search and random search hyperparameter tuning techniques to a house prediction problem and evaluated the model performance. In this lesson, we will present insights on when to use different cross-validation strategies. We will also discuss model evaluation metrics and introduce the notion of having a baseline model to compare with our model performance.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "n6Qj1bKnAhzH"
   },
   "source": [
    "## **1. Model Evaluation**\n",
    "\n",
    "In the previous modules, we have encountered different learning algorithms, and in all of them, we are interested in minimizing errors when presented with never-before-seen data. To achieve this, we will discuss the following concepts in this section:\n",
    "1. Choosing an appropriate cross-validation strategy.\n",
    "2. Building a baseline model that acts as a reference for the actual model.\n",
    "3. Nested cross-validation concepts and their evaluation.\n",
    "4. Metrics used in classification and regression models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "Yp5Q1EPQB7GD"
   },
   "source": [
    "### **1.1 Building Baseline Models**\n",
    "\n",
    "The baseline model can be thought of as a model reference to the actual model. We should consider the following points when building a baseline model:\n",
    "1. It should be a simple model that is used for comparison.\n",
    "2. It should be easy to explain.\n",
    "3. It should be based on the actual data.\n",
    "\n",
    "Baseline models are important for the following reasons;\n",
    "\n",
    "**Understanding the Data**\n",
    "\n",
    "When we train a baseline model on our dataset, we can infer the following:\n",
    "- A baseline model where prediction of our target variable is completely off indicates how difficult it will be for weaker models to get patterns in the dataset.\n",
    "- It can help us point out the segment of the data that gives the model a higher error.\n",
    "\n",
    "**Faster Modeling**\n",
    "\n",
    "Once we have a baseline model in place, building the actual model pipeline becomes easier as we understand the data better.\n",
    "\n",
    "**Performance Benchmark**\n",
    "\n",
    "The performance of the baseline model help us to decide whether we will need a complex model or a simple one.\n",
    "\n",
    "We can divide the baseline model into two types:\n",
    "1. Simple baseline model.\n",
    "2. Machine learning baseline model.\n",
    "\n",
    "In this subsection, we will consider a simple baseline model that uses simple logic to build the baseline model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "id": "d9nOLS2JHVY0"
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "\n",
    "data, target = fetch_california_housing(return_X_y=True, as_frame=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "8O9cBFyR4glb"
   },
   "source": [
    "We split the data using `ShuffleSplit` with $20\\%$ of the data used for validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "id": "3bsmaLL-HVbd"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "cv = ShuffleSplit(n_splits=30, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "ZMq8Fgk544eQ"
   },
   "source": [
    "We define a decision tree regression function as our model for this section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "id": "hfBNi0L3HVd_"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "regressor = DecisionTreeRegressor()\n",
    "cv_results_tree_regressor = cross_validate(\n",
    "    regressor, data, target, cv=cv, scoring=\"neg_mean_absolute_error\", n_jobs=2\n",
    ")\n",
    "\n",
    "errors_tree_regressor = pd.Series(\n",
    "    -cv_results_tree_regressor[\"test_score\"], name=\"Decision tree regressor\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "9hP5x_Mj5k9q"
   },
   "source": [
    "We use a dummy regressor as our baseline that predicts the mean of the target computed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "deletable": false,
    "id": "yNYxdzM7HVg3",
    "outputId": "0d5284db-7b76-4c8a-e60d-5fd8ef2a2a2c"
   },
   "outputs": [],
   "source": [
    "from sklearn.dummy import DummyRegressor\n",
    "\n",
    "dummy = DummyRegressor(strategy=\"mean\")\n",
    "result_dummy = cross_validate(\n",
    "    dummy, data, target, cv=cv, scoring=\"neg_mean_absolute_error\", n_jobs=2\n",
    ")\n",
    "errors_dummy_regressor = pd.Series(-result_dummy[\"test_score\"], name=\"Dummy regressor\")\n",
    "errors_dummy_regressor.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "ZHTDmN-E53E2"
   },
   "source": [
    "In the next cell, we prepare a table that compares the performance of the decision tree regressor and the dummy regressor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 990
    },
    "deletable": false,
    "id": "PvS8YDw2HVkV",
    "outputId": "9a29105a-e19d-4492-9b86-11dc5d897f8f"
   },
   "outputs": [],
   "source": [
    "all_errors = pd.concat(\n",
    "    [errors_tree_regressor, errors_dummy_regressor],\n",
    "    axis=1,\n",
    ")\n",
    "all_errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "9tTjYBfw6Kzx"
   },
   "source": [
    "We see from the table above that in all the splits, the decision tree regressor has fewer errors compared to the dummy regressor. In the next cell, we can visualize the distribution of errors for both regression functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 308
    },
    "deletable": false,
    "id": "EO6VjQOsNlSI",
    "outputId": "1cfaa331-771c-4da3-acaa-610aacd5a0de"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "bins = np.linspace(start=0, stop=1, num=80)\n",
    "all_errors.plot.hist(bins=bins, edgecolor=\"black\")\n",
    "plt.legend(bbox_to_anchor=(1.05, 0.8), loc=\"upper left\")\n",
    "plt.xlabel(\"Mean absolute error\")\n",
    "plt.suptitle(\n",
    "    \"Fig. 1: Cross-validation testing errors.\",\n",
    "    fontweight=\"bold\",\n",
    "    horizontalalignment=\"right\",\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "3tJd7-EDUEnD"
   },
   "source": [
    "### **1.2 Choosing a Cross-Validation Strategy**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "R8VhpAfd8cx8"
   },
   "source": [
    "So far we have only used `ShuffleSplit` or `KFold` to perform cross-validation, but they may not work all the time. As such, it's important to choose a cross-validation strategy wisely, depending on the task at hand. Let's consider the example below to demonstrate why it is important to choose a cross-validation strategy carefully."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "id": "2TY8etWaT_52"
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "\n",
    "data, target = load_iris(as_frame=True, return_X_y=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "aGLxGnku_VJH"
   },
   "source": [
    "We now create a simple classification algorithm for this task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "id": "DKE9rVr1UrJP"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "model = make_pipeline(StandardScaler(), LogisticRegression())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "b1ZPh2pR8ZSK"
   },
   "source": [
    "We now use this model to train and generalize on unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "deletable": false,
    "id": "Q-T2ShNlUrRs",
    "outputId": "aacb02ed-386c-4e60-b538-394d467f5119"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold, cross_validate\n",
    "\n",
    "cv = KFold(n_splits=3)\n",
    "results = cross_validate(model, data, target, cv=cv)\n",
    "test_score = results[\"test_score\"]\n",
    "print(f\"The average accuracy is \" f\"{test_score.mean():.3f} ± {test_score.std():.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "uhgZ4rl88fIr"
   },
   "source": [
    "The output above shows that the model was unable to get any prediction correct when exposed to validation data. To understand this peculiar output, we investigate the target feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 308
    },
    "deletable": false,
    "id": "uDYlXgatVAJE",
    "outputId": "5c33ad4f-5a87-4e8e-9294-81f81e265c54"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "target.plot()\n",
    "plt.xlabel(\"Sample index\")\n",
    "plt.ylabel(\"Class\")\n",
    "plt.yticks(target.unique())\n",
    "plt.suptitle(\n",
    "    \"Fig. 2: Class value in target y.\", fontweight=\"bold\", horizontalalignment=\"right\"\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "wH-heT359PPt"
   },
   "source": [
    "We can observe from the above diagram that the target column is ordered, and this causes an unexpected outcome when we use cross-validation. We will now compute the class counts for the training and validation sets in the cells below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "id": "XjV9PtUxVAL1"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "n_splits = 3\n",
    "cv = KFold(n_splits=n_splits)\n",
    "\n",
    "train_cv_counts = []\n",
    "test_cv_counts = []\n",
    "for fold_idx, (train_idx, test_idx) in enumerate(cv.split(data, target)):\n",
    "    target_train, target_test = target.iloc[train_idx], target.iloc[test_idx]\n",
    "\n",
    "    train_cv_counts.append(target_train.value_counts())\n",
    "    test_cv_counts.append(target_test.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "TN_65qmd-J16"
   },
   "source": [
    "We display this in the table below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 175
    },
    "deletable": false,
    "id": "e561oWMGUrU0",
    "outputId": "018cc221-24f0-4933-9774-7df95c73649c"
   },
   "outputs": [],
   "source": [
    "train_cv_counts = pd.concat(\n",
    "    train_cv_counts, axis=1, keys=[f\"Fold #{idx}\" for idx in range(n_splits)]\n",
    ")\n",
    "train_cv_counts.index.name = \"Class label\"\n",
    "train_cv_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "hWzWNGas-N_G"
   },
   "source": [
    "We can see that when training the model, in each fold, only two of the classes are available, and thus, it becomes difficult to predict on unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 175
    },
    "deletable": false,
    "id": "dksnNC_-UrXt",
    "outputId": "66fc2cc9-3815-4d6b-d7ac-0309d3e3bcb2"
   },
   "outputs": [],
   "source": [
    "test_cv_counts = pd.concat(\n",
    "    test_cv_counts, axis=1, keys=[f\"Fold #{idx}\" for idx in range(n_splits)]\n",
    ")\n",
    "test_cv_counts.index.name = \"Class label\"\n",
    "test_cv_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "wIi92u9h-hn7"
   },
   "source": [
    "In the test data, only one class, which was not available in training, is used. This makes it difficult to predict, as the class was not available when training. The cells below helps visualize the above tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 305
    },
    "deletable": false,
    "id": "aGPMSm-bVShu",
    "outputId": "8249008c-f099-4d1a-8f9b-484fe647f0ce"
   },
   "outputs": [],
   "source": [
    "train_cv_counts.plot.bar()\n",
    "plt.legend(bbox_to_anchor=(1.05, 0.8), loc=\"upper left\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.suptitle(\n",
    "    \"Fig. 3: Training Set Data Distribution in Folds.\",\n",
    "    fontweight=\"bold\",\n",
    "    horizontalalignment=\"right\",\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 305
    },
    "deletable": false,
    "id": "cDVKS9CRVSks",
    "outputId": "cc9f115d-7015-4130-fd41-b5940d90474d"
   },
   "outputs": [],
   "source": [
    "test_cv_counts.plot.bar()\n",
    "plt.legend(bbox_to_anchor=(1.05, 0.8), loc=\"upper left\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.suptitle(\n",
    "    \"Fig. 4: Data distribution in Testing Set\",\n",
    "    fontweight=\"bold\",\n",
    "    horizontalalignment=\"right\",\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "D4ivrXdG_CW3"
   },
   "source": [
    "To solve the problems above, it is a good practice to shuffle our dataset before we start the modeling phase as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "deletable": false,
    "id": "2OHQaDdCVSna",
    "outputId": "4b29a9b9-e61e-45b7-bec7-e523fb123c12"
   },
   "outputs": [],
   "source": [
    "cv = KFold(n_splits=3, shuffle=True, random_state=0)\n",
    "results = cross_validate(model, data, target, cv=cv)\n",
    "test_score = results[\"test_score\"]\n",
    "print(f\"The average accuracy is \" f\"{test_score.mean():.3f} ± {test_score.std():.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "HBC7KhsQ_Ng6"
   },
   "source": [
    "We can now see that the model accuracy has really improved to more than $95\\%$. We can now visualize the count of class in each fold for both the training and testing samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "id": "5EMtmqlLVSp9"
   },
   "outputs": [],
   "source": [
    "train_cv_counts = []\n",
    "test_cv_counts = []\n",
    "for fold_idx, (train_idx, test_idx) in enumerate(cv.split(data, target)):\n",
    "    target_train, target_test = target.iloc[train_idx], target.iloc[test_idx]\n",
    "\n",
    "    train_cv_counts.append(target_train.value_counts())\n",
    "    test_cv_counts.append(target_test.value_counts())\n",
    "train_cv_counts = pd.concat(\n",
    "    train_cv_counts, axis=1, keys=[f\"Fold #{idx}\" for idx in range(n_splits)]\n",
    ")\n",
    "test_cv_counts = pd.concat(\n",
    "    test_cv_counts, axis=1, keys=[f\"Fold #{idx}\" for idx in range(n_splits)]\n",
    ")\n",
    "train_cv_counts.index.name = \"Class label\"\n",
    "test_cv_counts.index.name = \"Class label\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 305
    },
    "deletable": false,
    "id": "KWm_25B4Vnns",
    "outputId": "94bc7901-1928-4014-8f8a-b439e676e49d"
   },
   "outputs": [],
   "source": [
    "train_cv_counts.plot.bar()\n",
    "plt.legend(bbox_to_anchor=(1.05, 0.8), loc=\"upper left\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.suptitle(\n",
    "    \"Fig. 5: Training set Data Distribution (kFold).\",\n",
    "    fontweight=\"bold\",\n",
    "    horizontalalignment=\"right\",\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "ptbZfm7B_8NR"
   },
   "source": [
    "From the bar plots above, we can observe that the classes are fairly distributed in each fold. This is also true on the testing dataset below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 305
    },
    "deletable": false,
    "id": "Z19nNgjnVnqg",
    "outputId": "92962a4b-8d68-47fc-abe7-f704fe1a7fa8"
   },
   "outputs": [],
   "source": [
    "test_cv_counts.plot.bar()\n",
    "plt.legend(bbox_to_anchor=(1.05, 0.8), loc=\"upper left\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.suptitle(\n",
    "    \"Fig. 6: Testing set Data Distribution (kFold).\",\n",
    "    fontweight=\"bold\",\n",
    "    horizontalalignment=\"right\",\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "yK1G93CeAW1N"
   },
   "source": [
    "Another technique will involve splitting our dataset so as to preserve the original class counts in each validation split. This is done using stratification as shown in the cells below. The steps will remain as what we have seen in the two strategies before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "id": "BaC48d8JVns-"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "cv = StratifiedKFold(n_splits=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "deletable": false,
    "id": "uh85uXuoV6gF",
    "outputId": "980714e1-27b4-487b-c971-661aaf6e5564"
   },
   "outputs": [],
   "source": [
    "results = cross_validate(model, data, target, cv=cv)\n",
    "test_score = results[\"test_score\"]\n",
    "print(f\"The average accuracy is \" f\"{test_score.mean():.3f} ± {test_score.std():.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "id": "kCmsCP2IV6i5"
   },
   "outputs": [],
   "source": [
    "train_cv_counts = []\n",
    "test_cv_counts = []\n",
    "for fold_idx, (train_idx, test_idx) in enumerate(cv.split(data, target)):\n",
    "    target_train, target_test = target.iloc[train_idx], target.iloc[test_idx]\n",
    "\n",
    "    train_cv_counts.append(target_train.value_counts())\n",
    "    test_cv_counts.append(target_test.value_counts())\n",
    "train_cv_counts = pd.concat(\n",
    "    train_cv_counts, axis=1, keys=[f\"Fold #{idx}\" for idx in range(n_splits)]\n",
    ")\n",
    "test_cv_counts = pd.concat(\n",
    "    test_cv_counts, axis=1, keys=[f\"Fold #{idx}\" for idx in range(n_splits)]\n",
    ")\n",
    "train_cv_counts.index.name = \"Class label\"\n",
    "test_cv_counts.index.name = \"Class label\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 305
    },
    "deletable": false,
    "id": "cC1vcVpSV6lg",
    "outputId": "57791c06-f923-4087-865c-84cf30af5509"
   },
   "outputs": [],
   "source": [
    "train_cv_counts.plot.bar()\n",
    "plt.legend(bbox_to_anchor=(1.05, 0.8), loc=\"upper left\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.suptitle(\n",
    "    \"Fig. 7: Training set Data Distribution (Stratified).\",\n",
    "    fontweight=\"bold\",\n",
    "    horizontalalignment=\"right\",\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 305
    },
    "deletable": false,
    "id": "AG4iyg-zWIt3",
    "outputId": "d0bfe03c-99c6-4545-ac82-50675890922b"
   },
   "outputs": [],
   "source": [
    "test_cv_counts.plot.bar()\n",
    "plt.legend(bbox_to_anchor=(1.05, 0.8), loc=\"upper left\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.suptitle(\n",
    "    \"Fig. 8: Testing set Data Distribution (Stratified).\",\n",
    "    fontweight=\"bold\",\n",
    "    horizontalalignment=\"right\",\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "tf04ck7GA4tk"
   },
   "source": [
    "We can see that the counts in the training and testing sets are not too far from each other."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "2MrK4nIALMXZ"
   },
   "source": [
    "### **1.3 Nested Cross-Validation**\n",
    "\n",
    "The k-fold cross validation technique that we have discussed so far is important for hyperparameter optimization and model evaluation on the validation set. The fact that we use cross-validation on the same dataset to tune our hyperparameters and choose a model from the same process may cause the model evaluation to be biased.\n",
    "\n",
    "A work-around to this limitation is to create an outer loop of cross-validation. This process is called **nested cross-validation** and we will demonstrate this in the cells below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "7979RdQzz9wG"
   },
   "source": [
    "We then configure the cross-validation process below. We will use the make classification dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "id": "AzlbtVl3SLw4"
   },
   "outputs": [],
   "source": [
    "from numpy import mean, std\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV, KFold, cross_val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "OF83eOeO5GzQ"
   },
   "source": [
    "We then split the dataset into a train and test dataset where the train dataset will also be used to train and validate the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "id": "sDccjIm84A50"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data, target, shuffle=True, random_state=0, test_size=0.3\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "E_Lv7SGO5jC7"
   },
   "source": [
    "We then define the model to be used for this problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "id": "6UkXvG5m3nY1"
   },
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "C470SFO_5td9"
   },
   "source": [
    "We now configure the inner cross-validation that will be used to train the hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "id": "o5eKbBIh5q6l"
   },
   "outputs": [],
   "source": [
    "cv_inner = KFold(n_splits=3, shuffle=True, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "MZJRHnZl5x3S"
   },
   "source": [
    "As we have seen from Lesson 1, we define the search space for our hyperparameters to be tuned and apply grid search to get the best combination of hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "id": "tnXE46YhSL4W"
   },
   "outputs": [],
   "source": [
    "space = dict()\n",
    "space[\"n_estimators\"] = [10, 100, 500]\n",
    "space[\"max_features\"] = [2, 4, 6]\n",
    "# Search for the best hyperparameter combination\n",
    "search = GridSearchCV(\n",
    "    model, space, scoring=\"accuracy\", n_jobs=1, cv=cv_inner, refit=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "c1Qo5maf6cux"
   },
   "source": [
    "We now configure the cross-validation that will help us evaluate the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "id": "F4UH4ALM2eU1"
   },
   "outputs": [],
   "source": [
    "cv_outer = KFold(n_splits=10, shuffle=True, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "cz3huVGR6ztJ"
   },
   "source": [
    "The next cell performs the nested cross validation on our data and we output the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "deletable": false,
    "id": "lP7USnsF2eva",
    "outputId": "8aebded7-2629-46c7-b578-6b25147a2b82"
   },
   "outputs": [],
   "source": [
    "# execute the nested cross-validation\n",
    "scores = cross_val_score(\n",
    "    search, X_train, y_train, scoring=\"accuracy\", cv=cv_outer, n_jobs=-1\n",
    ")\n",
    "# report performance\n",
    "print(\"Accuracy: %.3f (%.3f)\" % (mean(scores), std(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "c0L7hKaP7Fdc"
   },
   "source": [
    "We get the average model accuracy from the 10 iterations, and the result shows that our model has a better accuracy. But in classification, we need to go beyond accuracy as a measurement of model performance. In the next section, we learn about classification metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "LDvMWtYX_G-V"
   },
   "source": [
    "## **2. Metrics in Machine Learning**\n",
    "\n",
    "When building machine learning models, we need to measure their performance, and understanding the type of metric to use is vital if we are to judge whether we are making progress or not. As we are all aware now, machine learning tasks can be divided into regression or classification, and they are treated differently when modeling and also when measuring their performance. We will start by looking at regression metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "34nhQYhN_QWv"
   },
   "source": [
    "### **2.1 Regression Metrics**\n",
    "\n",
    "Linear regression involves finding the linear relationship that exists between the independent variables and the target variable, that is,\n",
    "$$y_i (x_i, w) = w_0 + w_1 x_{i1} + w_2 x_{i2} + \\cdots w_m x_{im} + ᵋ_i$$\n",
    "where $y\\in \\mathbb{R}$ is the target variable, $x \\in \\mathbb{R}^m$ is the predictor variables and $ᵋ_i$ is the random error. The random error occurs as a result of one of the following\n",
    "- Choosing a wrong linear model.\n",
    "- Selecting less relevant variables and omitting relevant ones.\n",
    "- Measurement errors.\n",
    "\n",
    "A good linear regression estimates the coefficient of the features, $w_i$, and minimizes the residual errors, $e_i = y_i  - \\hat{y}_i$. This is possible by minimizing the objective function. The objective function can take one of the forms below.\n",
    " \n",
    "\n",
    " #### **2.1.1 Mean Squared Error (MSE)**\n",
    " The mean squared error is given by $$L = \\frac{1}{n} \\sum_{i=1}^n (\\hat{y}_i - y_i)^2$$\n",
    "\n",
    " #### **2.1.2 Mean Absolute Error (MAE)**\n",
    "\n",
    " The mean absolute error is given by\n",
    " $$L = \\frac{1}{n} \\sum_{i=1}^n |\\hat{y}_i - y_i|$$\n",
    "\n",
    " #### **2.1.3 Mean Squared Logarithmic Error**\n",
    "\n",
    " This is similar to MSE, but the dependent variable is in logarithmic scale:\n",
    " $$L = \\frac{1}{n} \\sum_{i=1}^n (\\log(\\hat{y}_i+1) - log(y_i+1))^2$$\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "d19Mbz3lxnTw"
   },
   "source": [
    "In the next cells, we will look at different objective functions in regression for measuring errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "id": "CT3lQp7YO4Kd"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data_train, data_test, target_train, target_test = train_test_split(\n",
    "    data, target, shuffle=True, random_state=0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "l4myqk88y8OF"
   },
   "source": [
    "We first train the data using a decision-tree regressor and then evaluate on the test dataset. In the next cells, we look at the various metrics used to evaluate machine learning models. We start with most commonly used metric, the mean squared error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "deletable": false,
    "id": "4UmoBpfrNR2k",
    "outputId": "f274aac9-1cc6-437c-9440-e38a6e8e30aa"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "regressor.fit(data_train, target_train)\n",
    "target_predicted = regressor.predict(data_train)\n",
    "\n",
    "print(\n",
    "    f\"Mean squared error on the training set: \"\n",
    "    f\"{mean_squared_error(target_train, target_predicted):.3f}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "VT2-BLAKJ1rF"
   },
   "source": [
    "We measure the mean squared error on the test data below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "deletable": false,
    "id": "oDzoZ4hgNR5t",
    "outputId": "06a42887-21c6-4c8a-83b2-e56c91f3a839"
   },
   "outputs": [],
   "source": [
    "target_predicted = regressor.predict(data_test)\n",
    "\n",
    "print(\n",
    "    f\"Mean squared error on the testing set: \"\n",
    "    f\"{mean_squared_error(target_test, target_predicted):.3f}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "HcRHB6VuNnY2"
   },
   "source": [
    "To calculate the coefficient of determination, $R^2$, we calculate the `score()` function as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "deletable": false,
    "id": "ub9X12pmNSB4",
    "outputId": "13fb7532-ee8b-435b-ecbe-d0faecd98cf6"
   },
   "outputs": [],
   "source": [
    "regressor.score(data_test, target_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "VA1dMAV-N0yW"
   },
   "source": [
    "We can also calculate the mean absolute error for our model as shown below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "deletable": false,
    "id": "CXJsskPvPe0X",
    "outputId": "96866dab-367a-4017-d17f-ee546c3e918d"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "target_predicted = regressor.predict(data_test)\n",
    "print(\n",
    "    f\"Mean absolute error: \" f\"{mean_absolute_error(target_test, target_predicted):.3f}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "7PzrnxYzPy47"
   },
   "source": [
    "The median absolute error is equally calculated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "deletable": false,
    "id": "QskcS3ZxPe3t",
    "outputId": "69a50007-6a09-4aa0-aa74-a4bfef179f69"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import median_absolute_error\n",
    "\n",
    "print(\n",
    "    f\"Median absolute error: \"\n",
    "    f\"{median_absolute_error(target_test, target_predicted):.3f} \"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "eYVtVUrAsIgU"
   },
   "source": [
    "#### **2.1.4 Regularization**\n",
    "\n",
    "Regularization techniques are used in instances where a regression model overfits. The objective of regularization is to add a penalty term to the objective function that regularizes the size of the parameters, that is,\n",
    "\n",
    "$$L = \\frac{1}{n} \\sum_{i=1}^n (\\hat{y}_i - y_i)^2 + \\lambda R(\\vec{w})$$\n",
    "where $R(\\vec{w})$ is the penalty term, a hyperparameter.\n",
    "\n",
    "The most commonly used regularization techniques are ridge regression and lasso regression.\n",
    "\n",
    " **1. Ridge Regression**\n",
    "\n",
    "Ridge regression adds an $L2$-norm term to the objective function. The term causes weight decay to the variables. The loss function of a ridge regression is given by\n",
    "$$L = \\frac{1}{n} \\sum_{i=1}^n (\\hat{y}_i - y_i)^2 + \\frac{\\lambda}{2}||w||^2$$\n",
    "\n",
    "The $\\lambda$ hyperparameter controls the amount of decay where larger values of $\\lambda$ increase decay and thus make the model more robust to multi-collinearity. Note that for the value of $\\lambda = 0$, ridge regression is equivalent to linear regression. An increase in the value of $\\lambda$ makes the coefficients of our model approach zero.\n",
    "\n",
    "We start by importing the libraries for this demonstration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "id": "uGMGMy3fsclU"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "sns.set_style(\"darkgrid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "MLuHmTw_SNtR"
   },
   "source": [
    "We import and split the dataset into train and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "id": "cyy9dPusRdo3"
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "\n",
    "X, y = fetch_california_housing(as_frame=True, return_X_y=True)\n",
    "X.head()\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=25\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "UzckzCJHSVCv"
   },
   "source": [
    "We build the ridge model below and fit it to the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "id": "djw-f7TZRkC4"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler\n",
    "\n",
    "steps = [\n",
    "    (\"scalar\", StandardScaler()),\n",
    "    (\"poly\", PolynomialFeatures(degree=2)),\n",
    "    (\"model\", Ridge()),\n",
    "]\n",
    "\n",
    "ridge_pipe = Pipeline(steps)\n",
    "ridge_pipe.fit(X_train, y_train)\n",
    "# Predicting the Test set results\n",
    "y_pred = ridge_pipe.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "d8ggn9PXSwWA"
   },
   "source": [
    "We apply k-Fold cross-validation on the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "deletable": false,
    "id": "lgvMFdePRqnY",
    "outputId": "f74b048a-f0ae-45a0-d4b0-bd2ba07537d3"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "accuracies = cross_val_score(estimator=ridge_pipe, X=X_train, y=y_train, cv=10)\n",
    "print(\"accuracy mean\", accuracies.mean())\n",
    "print(\"accuracy standard deviation\", accuracies.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "_Cxgno_ZTOZe"
   },
   "source": [
    "We apply grid search to find the best model and the best alpha parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "id": "leltyjt9RuaN"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "parameters = [{\"model__alpha\": np.arange(0, 0.2, 0.01)}]\n",
    "\n",
    "scoring_func = make_scorer(mean_squared_error)\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=ridge_pipe, param_grid=parameters, scoring=scoring_func, cv=10, n_jobs=-1\n",
    ")\n",
    "grid_search = grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "q_JCBpI6QTw4"
   },
   "source": [
    "In the cell below, we display the alpha values that we intend to tune.<span style='color: transparent; font-size:1%'>All rights reserved WQU WorldQuant University QQQQ</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "deletable": false,
    "id": "j9136C0IVCbt",
    "outputId": "c36746f7-e32c-45ae-dc4d-e00285f5fee4"
   },
   "outputs": [],
   "source": [
    "grid_search.cv_results_[\"params\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "4meCdehhQqX1"
   },
   "source": [
    "As discussed in the model evaluation section, we will evaluate the performance of ridge regression on the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "id": "CKFpuoknsMYc"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso, LinearRegression\n",
    "from sklearn.model_selection import (\n",
    "    GridSearchCV,\n",
    "    KFold,\n",
    "    RepeatedKFold,\n",
    "    cross_validate,\n",
    "    train_test_split,\n",
    ")\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "67QbWVpkTku1"
   },
   "source": [
    "We apply linear regression in the dataset and generate prediction on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "deletable": false,
    "id": "QlW9xnMQsMdt",
    "outputId": "242e29b1-86bb-41b7-cd2f-6c140575a1fd"
   },
   "outputs": [],
   "source": [
    "lreg = LinearRegression()\n",
    "lreg.fit(X_train, y_train)\n",
    "\n",
    "lreg_y_pred = lreg.predict(X_test)\n",
    "\n",
    "# calculating Mean Squared Error (MSE)\n",
    "mean_squared_error = np.mean((lreg_y_pred - y_test) ** 2)\n",
    "print(\"Mean squared Error on test set : \", mean_squared_error)\n",
    "\n",
    "# Putting together the coefficient and their corresponding variable names\n",
    "lreg_coefficient = pd.DataFrame()\n",
    "lreg_coefficient[\"Columns\"] = X_train.columns\n",
    "lreg_coefficient[\"Coefficient Estimate\"] = pd.Series(lreg.coef_)\n",
    "print(lreg_coefficient)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "kbL38rBFT9Iz"
   },
   "source": [
    "In the next cell, we display the feature coefficients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 646
    },
    "deletable": false,
    "id": "OTkj4HCfsMg9",
    "outputId": "47b6b5b4-0edd-4500-c8a7-38534cc4851e"
   },
   "outputs": [],
   "source": [
    "# plotting the coefficient score\n",
    "fig, ax = plt.subplots(figsize=(20, 10))\n",
    "\n",
    "ax.bar(\n",
    "    lreg_coefficient[\"Columns\"],\n",
    "    lreg_coefficient[\"Coefficient Estimate\"],\n",
    ")\n",
    "\n",
    "ax.spines[\"bottom\"].set_position(\"zero\")\n",
    "\n",
    "plt.style.use(\"ggplot\")\n",
    "plt.suptitle(\n",
    "    \"Fig. 9: Coefficients Scores.\", fontweight=\"bold\", horizontalalignment=\"right\"\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "deletable": false,
    "id": "J7ErFAUwsMvm",
    "outputId": "bc87e078-9850-4590-d914-0bd0b766a699"
   },
   "outputs": [],
   "source": [
    "# import ridge regression from `sklearn` library\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "# Train the model\n",
    "ridgeR = Ridge(alpha=1)\n",
    "ridgeR.fit(X_train, y_train)\n",
    "y_pred = ridgeR.predict(X_test)\n",
    "\n",
    "# calculate mean square error\n",
    "mean_squared_error_ridge = np.mean((y_pred - y_test) ** 2)\n",
    "print(mean_squared_error_ridge)\n",
    "\n",
    "# get ridge coefficient and print them\n",
    "ridge_coefficient = pd.DataFrame()\n",
    "ridge_coefficient[\"Columns\"] = X_train.columns\n",
    "ridge_coefficient[\"Coefficient Estimate\"] = pd.Series(ridgeR.coef_)\n",
    "print(ridge_coefficient)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "1JAhyatktjgD"
   },
   "source": [
    "**2. Lasso Regression**\n",
    "\n",
    "Lasso (Least Absolute Shrinkage and Selection Operator) is another regularization model that adds an $L1$-term to the objective function. It works by equating irrelevant parameters to zero. The loss function of a lasso regression is given by \n",
    "\n",
    "$$L = \\frac{1}{n} \\sum_{i=1}^n (\\hat{y}_i - y_i)^2 + \\frac{\\lambda}{2}||w||$$\n",
    "\n",
    "Just like in ridge regression, $\\lambda$ controls  the penalty's strength. Just like ridge regression above, when $\\lambda = 0$, we have a linear regression equation. As the value of $\\lambda$ increases shrinkage to unimportant features and some will be equal to zero, the variance of the model reduces and bias increases.\n",
    "\n",
    "In the cells below, we demonstrate how to apply lasso on our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "id": "HJdQ4qbit_Ij"
   },
   "outputs": [],
   "source": [
    "steps = [(\"scalar\", StandardScaler()), (\"model\", Lasso())]\n",
    "\n",
    "lasso_pipe = Pipeline(steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "UbAFCNKNUWZ9"
   },
   "source": [
    "We apply cross-validation and print out the mean absolute error and the best alpha value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "deletable": false,
    "id": "RugH60MEtwQQ",
    "outputId": "a58edd93-b90f-4e4b-f876-732a6f940508"
   },
   "outputs": [],
   "source": [
    "cv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "model__alpha = np.linspace(0.1, 2, 21)\n",
    "lasso = Lasso()\n",
    "grid = dict()\n",
    "grid[\"model__alpha\"] = model__alpha\n",
    "gscv = GridSearchCV(\n",
    "    lasso_pipe, grid, scoring=\"neg_mean_absolute_error\", cv=cv, n_jobs=-1\n",
    ")\n",
    "results = gscv.fit(X, y)\n",
    "print(\"MAE: %.5f\" % results.best_score_)\n",
    "print(\"Config: %s\" % results.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "s5D5meppUqQ_"
   },
   "source": [
    "We can now import the libraries and compute the model metric below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "deletable": false,
    "id": "7pMEeZ1ytACp",
    "outputId": "977bf02b-74f9-4683-ece3-e341b60d3dcd"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "# Train the model\n",
    "lasso = Lasso(alpha=1)\n",
    "lasso.fit(X_train, y_train)\n",
    "y_pred1 = gscv.predict(X_test)\n",
    "\n",
    "# Calculate Mean Squared Error\n",
    "mean_squared_error = np.mean((y_pred1 - y_test) ** 2)\n",
    "print(\"Mean squared error on test set\", mean_squared_error)\n",
    "lasso_coeff = pd.DataFrame()\n",
    "lasso_coeff[\"Columns\"] = X_train.columns\n",
    "lasso_coeff[\"Coefficient Estimate\"] = pd.Series(lasso.coef_)\n",
    "\n",
    "print(lasso_coeff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "akp1-Jq176jO"
   },
   "source": [
    "From the results above, we see the coefficients of features not relevant rounded down to zero."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "Q3Nji75D_cdi"
   },
   "source": [
    "### **2.2 Classification Metrics**\n",
    "\n",
    "In the next cells, we are going to discuss and demonstrate different classification metrics on the iris dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "id": "DrSKVFUJRLJr"
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data, target = load_iris(as_frame=True, return_X_y=True)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data, target, shuffle=True, random_state=0, test_size=0.3\n",
    ")\n",
    "\n",
    "model = RandomForestClassifier(random_state=1)\n",
    "model.fit(X_train, y_train)\n",
    "target_predicted = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "wJYjOYiIWSOB"
   },
   "source": [
    "**Accuracy**\n",
    "\n",
    "We use accuracy as a baseline. Accuracy simply finds the proportion of classes we classified correctly, that is, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "deletable": false,
    "id": "ZhHy0i3_U8kW",
    "outputId": "0511aeb0-e4a8-4be5-9635-e5b1302cf2db"
   },
   "outputs": [],
   "source": [
    "y_test == target_predicted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "7Opz0bYRW5Ah"
   },
   "source": [
    "To get the accuracy of our model, we get the mean of the number of times we predicted correctly as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "deletable": false,
    "id": "YZTdUBofU8nA",
    "outputId": "c315e6b4-2b78-4969-fdfa-12944456db23"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.round(np.mean(y_test == target_predicted), 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "uXEUWr5OXRxT"
   },
   "source": [
    "This is implemented in `sklearn` using the `accuracy_score` as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "deletable": false,
    "id": "fe7naGGaU8uG",
    "outputId": "5f0ec1ce-598e-4188-9c12-12309c98a90d"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy = accuracy_score(y_test, target_predicted)\n",
    "print(f\"Accuracy: {accuracy:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "QHj3KhzLXwhf"
   },
   "source": [
    "**Confusion Matrix**\n",
    "\n",
    "Accuracy might not be a good measure of a model performance, especially when the target variable is imbalanced. The most common class will always have more weight. To get the finer details of the model performance, it is recommended to construct a confusion matrix to independently determine what error is for each class. The cell below shows how to construct a confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 311
    },
    "deletable": false,
    "id": "hyAEBwE5XHVZ",
    "outputId": "67384a40-47c5-476e-e825-580b97cc1a7f"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "_ = ConfusionMatrixDisplay.from_estimator(model, X_test, y_test)\n",
    "plt.suptitle(\n",
    "    \"Fig. 10: Confusion Matrix.\", fontweight=\"bold\", horizontalalignment=\"right\"\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "c8Hx3w2sZB5T"
   },
   "source": [
    "The diagonal entries represent the correct predictions and the off-diagonal entries are the incorrect predictions. For more on confusion matrices, we ask students to read [A Review on Evaluation Metrics for Data Classification Evaluations.](https://airccse.org/journal/ijdkp/vol5.html#mar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "3ybKRBzRuBvj"
   },
   "source": [
    "\n",
    "## **3. Conclusion**\n",
    "\n",
    "In this lesson we discussed simulated annealing as one of the techniques for hyperparameter tuning and also introduced objective functions in machine learning. In the next lesson we are going to see how we can apply Bayesian hyperparameter tuning in a bitcoin trading strategy. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "7-X-AarjuF9Y"
   },
   "source": [
    "**References**\n",
    "\n",
    "1. Ampatzis, Christos, and Dario Izzo. \"Machine Learning Techniques for Approximation of Objective Functions in Trajectory Optimisation.\" Proceedings of the IJCAI-09 workshop on Artificial Intelligence in Space, 2009.\n",
    "2. Botchkarev, Alexei. \"Evaluating Performance of Regression Machine Learning Models Using Multiple Error Metrics in Azure Machine Learning Studio.\" 2018.\n",
    "3. Hossin, Mohammad, and Md Nasir Sulaiman. \"A Review on Evaluation Metrics for Data Classification Evaluations.\" *International Journal of Data Mining & Knowledge Management Process*, vol 5, no. 2, 2015."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "---\n",
    "Copyright 2023 WorldQuant University. This\n",
    "content is licensed solely for personal use. Redistribution or\n",
    "publication of this material is strictly prohibited.\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
