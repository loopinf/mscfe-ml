{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5AxF11X9tHvo"
   },
   "source": [
    "\n",
    "## MACHINE LEARNING IN FINANCE\n",
    "MODULE 7 | LESSON 4\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J4ceGgiItOf0"
   },
   "source": [
    "# **BITCOIN TRADING STRATEGY**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MELzJ6aRtXsV"
   },
   "source": [
    "\n",
    "|  |  |\n",
    "|:---|:---|\n",
    "|**Reading Time** |  30 minutes |\n",
    "|**Prior Knowledge** | Hyperparameter tuning, supervised machine learning, classification algorithms  |\n",
    "|**Keywords** |Bayesian optimization, signal  |\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mg7hqOaYt6Be"
   },
   "source": [
    "*In the last lesson, we discussed objective functions and extended our knowledge on hyperparameter tuning. In this lesson, we will train classification algorithms on a Bitcoin trading strategy problem and improve the performance of one machine learning model by tuning its parameters using grid search and Bayesian optimization techniques.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wFj_Spe5Z9wk"
   },
   "source": [
    "## **1. Introduction**\n",
    "\n",
    "In this problem we want to predict when to buy or sell Bitcoin. We will start by defining a *buy or sell signal* that will be represented by 1 or 0. We arrive at the signal by comparing the price trend of short-term and long-term behavior, that is, a short-term moving average greater than a long-term moving average. Then, we buy bitcoin; otherwise, we sell bitcoin. This is, therefore, a classification problem where we are interested in getting the direction of Bitcoin movement right. We will split our dataset into train and validation sets in the ratio of 4:1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kw4vpqbIFe0S"
   },
   "source": [
    "## **2. Loading Helper Packages and Data**\n",
    "\n",
    "### **2.1 Loading Helper Packages**\n",
    "\n",
    "We load the Python packages that will assist us in achieving our objective."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZGMr98dKBwTF"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bVXqym-1HZVS",
    "outputId": "ad2c6773-ecc6-48d2-e45b-0fe7bd2c5025"
   },
   "outputs": [],
   "source": [
    "from time import time\n",
    "\n",
    "import joblib\n",
    "\n",
    "# display all columns\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option(\"display.max_rows\", None)\n",
    "\n",
    "\n",
    "from bayes_opt import BayesianOptimization\n",
    "\n",
    "# Libraries for Deep Learning Models\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.ensemble import (\n",
    "    AdaBoostClassifier,\n",
    "    GradientBoostingClassifier,\n",
    "    RandomForestClassifier,\n",
    ")\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# needed for `HistGradientBoostingClassifier`\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    f1_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    ")\n",
    "from sklearn.model_selection import (\n",
    "    GridSearchCV,\n",
    "    KFold,\n",
    "    StratifiedKFold,\n",
    "    cross_val_score,\n",
    "    cross_validate,\n",
    "    train_test_split,\n",
    ")\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# from `keras.optimizers` import SGD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vompwon5GNDA"
   },
   "source": [
    "### **2.2 Data Loading**\n",
    "\n",
    "We fetch Bitcoin data price from Yahoo finance for the last five years."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CM4Q49_sCYY9"
   },
   "outputs": [],
   "source": [
    "# To fetch financial data\n",
    "import yfinance as yf\n",
    "\n",
    "# Set the ticker as 'BTC-USD'\n",
    "BTC_Ticker = yf.Ticker(\"BTC-USD\")\n",
    "BTC_Data = BTC_Ticker.history(period=\"5y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 238
    },
    "id": "Lb6EW_GVEwUK",
    "outputId": "b340470e-94f0-4105-d9e2-ff32cc20478e"
   },
   "outputs": [],
   "source": [
    "# BTC_Ticker = yf.Ticker(\"BTC-USD\")\n",
    "# BTC_Data = BTC_Ticker.history(period=\"max\")\n",
    "BTC_Data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WvJdsGuAG1HO"
   },
   "source": [
    "### **3. Exploratory Data Analysis (EDA)**\n",
    "\n",
    "This stage explores the data to help us see trends in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g40jFRYJZCCr",
    "outputId": "7afb2850-aead-41cd-c991-1921e0fec825"
   },
   "outputs": [],
   "source": [
    "BTC_Data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Fjds_Zl3HEW2",
    "outputId": "b1fc1788-cd03-4f64-aafb-7dfaecc0714d"
   },
   "outputs": [],
   "source": [
    "BTC_Data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "id": "8n8vSf3OHRzn",
    "outputId": "62902def-1e42-4c61-a805-bbaa18473ee7"
   },
   "outputs": [],
   "source": [
    "BTC_Data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5vwE1WwThhOf",
    "outputId": "8c7d6b03-0dcb-4dfc-b9c8-5121a3327405"
   },
   "outputs": [],
   "source": [
    "# Checking for any null values and removing the null values'''\n",
    "print(\"Null Values =\", BTC_Data.isnull().values.any())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yJ-G7HaBIbaa"
   },
   "source": [
    "## **4. Data Preparation**\n",
    "\n",
    "We start by creating our target variable, that is, the buy or sell signal. The target variable constitutes our trading strategy. When the shorter term moving average goes above the longer term moving average, then it is an indicator to buy and the vice versa is also true. Read more here: [Picking buy-sell signals: A practitioner's perspective on key technical indicators for selected Indian firms.](https://sciendo.com/article/10.2478/sbe-2019-0054)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ClcCZ1fmjD8F"
   },
   "outputs": [],
   "source": [
    "# Create short simple moving average over the short window\n",
    "BTC_Data[\"short_moving_avg\"] = (\n",
    "    BTC_Data[\"Close\"].rolling(window=10, min_periods=1, center=False).mean()\n",
    ")\n",
    "\n",
    "# Create long simple moving average over the long window\n",
    "BTC_Data[\"long_maving_avg\"] = (\n",
    "    BTC_Data[\"Close\"].rolling(window=60, min_periods=1, center=False).mean()\n",
    ")\n",
    "\n",
    "# Create signals\n",
    "BTC_Data[\"signal\"] = np.where(\n",
    "    BTC_Data[\"short_moving_avg\"] > BTC_Data[\"long_maving_avg\"], 1.0, 0.0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 406
    },
    "id": "Ywioyz4OmK6t",
    "outputId": "ed0f3c83-9ccf-4f2b-8192-44edbcb93f81"
   },
   "outputs": [],
   "source": [
    "BTC_Data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tLJZFzE6LaxO"
   },
   "source": [
    "### **4.1 Feature Engineering**\n",
    "\n",
    "We now create additional features in our dataset that will help improve our model performance. The additional features are:\n",
    "1. Exponential Moving Average: This gives us the price trend of the data.\n",
    "2. Relative Strength Indicator (RSI): RSI measures the change in prices in a recent time frame.\n",
    "3. Rate of Change: This measures the percentage change between the stock's current price and past prices.\n",
    "4. Stochastic Oscillator: This compares the current closing price of a stock with its previous closing prices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h_SerFwBnoz8"
   },
   "outputs": [],
   "source": [
    "# calculation of exponential moving average\n",
    "def EMA(df, n):\n",
    "    EMA = pd.Series(df[\"Close\"].ewm(span=n, min_periods=n).mean(), name=\"EMA_\" + str(n))\n",
    "    return EMA\n",
    "\n",
    "\n",
    "BTC_Data[\"EMA10\"] = EMA(BTC_Data, 10)\n",
    "BTC_Data[\"EMA30\"] = EMA(BTC_Data, 30)\n",
    "BTC_Data[\"EMA200\"] = EMA(BTC_Data, 200)\n",
    "BTC_Data.head()\n",
    "\n",
    "\n",
    "# calculation of rate of change\n",
    "def RC(df, n):\n",
    "    M = df.diff(n - 1)\n",
    "    N = df.shift(n - 1)\n",
    "    RC = pd.Series(((M / N) * 100), name=\"RC_\" + str(n))\n",
    "    return RC\n",
    "\n",
    "\n",
    "BTC_Data[\"RC10\"] = RC(BTC_Data[\"Close\"], 10)\n",
    "BTC_Data[\"RC30\"] = RC(BTC_Data[\"Close\"], 30)\n",
    "\n",
    "\n",
    "# Calculation of price momentum\n",
    "def MOM(df, n):\n",
    "    MOM = pd.Series(df.diff(n), name=\"Momentum_\" + str(n))\n",
    "    return MOM\n",
    "\n",
    "\n",
    "BTC_Data[\"MOM10\"] = MOM(BTC_Data[\"Close\"], 10)\n",
    "BTC_Data[\"MOM30\"] = MOM(BTC_Data[\"Close\"], 30)\n",
    "\n",
    "\n",
    "# calculation of relative strength index\n",
    "def RSI(series, period):\n",
    "    delta = series.diff().dropna()\n",
    "    u = delta * 0\n",
    "    d = u.copy()\n",
    "    u[delta > 0] = delta[delta > 0]\n",
    "    d[delta < 0] = -delta[delta < 0]\n",
    "    u[u.index[period - 1]] = np.mean(u[:period])  # first value is sum of avg gains\n",
    "    u = u.drop(u.index[: (period - 1)])\n",
    "    d[d.index[period - 1]] = np.mean(d[:period])  # first value is sum of avg losses\n",
    "    d = d.drop(d.index[: (period - 1)])\n",
    "    rs = (\n",
    "        u.ewm(com=period - 1, adjust=False).mean()\n",
    "        / d.ewm(com=period - 1, adjust=False).mean()\n",
    "    )\n",
    "    return 100 - 100 / (1 + rs)\n",
    "\n",
    "\n",
    "BTC_Data[\"RSI10\"] = RSI(BTC_Data[\"Close\"], 10)\n",
    "BTC_Data[\"RSI30\"] = RSI(BTC_Data[\"Close\"], 30)\n",
    "BTC_Data[\"RSI200\"] = RSI(BTC_Data[\"Close\"], 200)\n",
    "\n",
    "# calculation of stochastic oscillator.\n",
    "\n",
    "\n",
    "def STOK(close, low, high, n):\n",
    "    STOK = (\n",
    "        (close - low.rolling(n).min()) / (high.rolling(n).max() - low.rolling(n).min())\n",
    "    ) * 100\n",
    "    return STOK\n",
    "\n",
    "\n",
    "def STOD(close, low, high, n):\n",
    "    STOK = (\n",
    "        (close - low.rolling(n).min()) / (high.rolling(n).max() - low.rolling(n).min())\n",
    "    ) * 100\n",
    "    STOD = STOK.rolling(3).mean()\n",
    "    return STOD\n",
    "\n",
    "\n",
    "BTC_Data[\"%K10\"] = STOK(BTC_Data[\"Close\"], BTC_Data[\"Low\"], BTC_Data[\"High\"], 10)\n",
    "BTC_Data[\"%D10\"] = STOD(BTC_Data[\"Close\"], BTC_Data[\"Low\"], BTC_Data[\"High\"], 10)\n",
    "BTC_Data[\"%K30\"] = STOK(BTC_Data[\"Close\"], BTC_Data[\"Low\"], BTC_Data[\"High\"], 30)\n",
    "BTC_Data[\"%D30\"] = STOD(BTC_Data[\"Close\"], BTC_Data[\"Low\"], BTC_Data[\"High\"], 30)\n",
    "BTC_Data[\"%K200\"] = STOK(BTC_Data[\"Close\"], BTC_Data[\"Low\"], BTC_Data[\"High\"], 200)\n",
    "BTC_Data[\"%D200\"] = STOD(BTC_Data[\"Close\"], BTC_Data[\"Low\"], BTC_Data[\"High\"], 200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4XZ48SnGQLvw"
   },
   "source": [
    "We can display the dataframe to look at the features we have just feature-engineered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 406
    },
    "id": "hFXWpt5Yno2t",
    "outputId": "e98318ef-ec6c-43f4-c9ea-ae4b24bab4ad"
   },
   "outputs": [],
   "source": [
    "BTC_Data.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z1TGjFJeQwUr"
   },
   "source": [
    "In the next cell, we calculate the moving average."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 406
    },
    "id": "C2OpUN29no5T",
    "outputId": "a6c47540-ba28-4f8a-d3b5-2a21e12dd7c1"
   },
   "outputs": [],
   "source": [
    "def MA(df, n):\n",
    "    MA = pd.Series(df[\"Close\"].rolling(n, min_periods=n).mean(), name=\"MA_\" + str(n))\n",
    "    return MA\n",
    "\n",
    "\n",
    "BTC_Data[\"MA21\"] = MA(BTC_Data, 10)\n",
    "BTC_Data[\"MA63\"] = MA(BTC_Data, 30)\n",
    "BTC_Data[\"MA252\"] = MA(BTC_Data, 200)\n",
    "BTC_Data.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aNOsBSAzQ6vU"
   },
   "source": [
    "We can now exclude features that are irrelevant for our prediction task such as the Bitcoin `High`, `Low` and `Open` values. Since we have already defined our trading signals, we drop the short and long moving average features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J6dfWsYQno74"
   },
   "outputs": [],
   "source": [
    "# excluding columns that are not needed for our prediction.\n",
    "\n",
    "BTC_Data = BTC_Data.drop(\n",
    "    [\n",
    "        \"High\",\n",
    "        \"Low\",\n",
    "        \"Open\",\n",
    "        \"short_moving_avg\",\n",
    "        \"long_maving_avg\",\n",
    "        \"Dividends\",\n",
    "        \"Stock Splits\",\n",
    "    ],\n",
    "    axis=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ywIKXQxKno-e"
   },
   "outputs": [],
   "source": [
    "BTC_Data = BTC_Data.dropna(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WCHH15soRirf"
   },
   "source": [
    "We can now visualize the Bitcoin price trend over the four years as shown in the figure below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 314
    },
    "id": "KLFSTgJznpBE",
    "outputId": "ea27a3fa-2b40-4b83-fba5-d078b149b1d0"
   },
   "outputs": [],
   "source": [
    "BTC_Data[[\"Close\"]].plot(grid=True)\n",
    "plt.suptitle(\n",
    "    \"Fig. 1: Bitcoin Price trend\", fontweight=\"bold\", horizontalalignment=\"right\"\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4pEnPdsZR3KF"
   },
   "source": [
    "In the cell below, we display the distribution of features that helps the modeler determine how to treat the individual features in our prediction dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 780
    },
    "id": "BaHEjzpknpDr",
    "outputId": "290776f2-ed99-45c7-df0e-510222448870"
   },
   "outputs": [],
   "source": [
    "# histograms\n",
    "BTC_Data.hist(sharex=False, sharey=False, xlabelsize=1, ylabelsize=1, figsize=(12, 12))\n",
    "plt.suptitle(\n",
    "    \"Fig. 2: Variable Distribution\", fontweight=\"bold\", horizontalalignment=\"right\"\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ci2FG9oNSGAL"
   },
   "source": [
    "Our interest as stated in the introduction is to predict when to buy or sell a Bitcoin. We draw a pie chart to visualize the proportion of sell to buy signals in our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 400
    },
    "id": "Cj1HW3k8npGc",
    "outputId": "69e3e4b9-3914-49d5-95d8-0f9dd7ad33cd"
   },
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "plot = (\n",
    "    BTC_Data.groupby(\"signal\")\n",
    "    .size()\n",
    "    .plot(kind=\"pie\", figsize=(6, 6), autopct=\"%1.1f%%\", y=\"Signal\")\n",
    ")\n",
    "plt.suptitle(\n",
    "    \"Fig. 3: A Pie Chart of buy and sell signal\",\n",
    "    fontweight=\"bold\",\n",
    "    horizontalalignment=\"right\",\n",
    ")\n",
    "plt.legend([\"sell\", \"buy\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T__ki3ExSfWb"
   },
   "source": [
    "The count of this signals can also be seen below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JtIoUPmqWnOL",
    "outputId": "c1825514-ffe7-4895-9e01-5c1368721b43"
   },
   "outputs": [],
   "source": [
    "BTC_Data.groupby([\"signal\"]).size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ne5LdTowdcDi"
   },
   "source": [
    "We can now look at the relationship between our variables using a correlation matrix of the returns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 954
    },
    "id": "-aeeTWwQnpMu",
    "outputId": "13a85b17-a894-4ea8-bed3-f25dc3ed29f4"
   },
   "outputs": [],
   "source": [
    "# correlation\n",
    "BTC_data_returns = BTC_Data.shift(1)\n",
    "correlation = BTC_data_returns.corr()\n",
    "plt.figure(figsize=(15, 15))\n",
    "plt.title(\"Correlation Matrix\")\n",
    "sns.heatmap(correlation, vmax=1, square=True, annot=True, cmap=\"RdBu\")\n",
    "plt.suptitle(\n",
    "    \"Fig. 4: Correlation Matrix of BITCOIN return\",\n",
    "    fontweight=\"bold\",\n",
    "    horizontalalignment=\"right\",\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vwk9IoawPDzP"
   },
   "source": [
    "## **5. Modeling**\n",
    "\n",
    "Now that we have our dataset in place, we split our dataset into a training and a holdout set, in our case the test set that will be used to backtest on our model. \n",
    "\n",
    "### **5.1 Train test Split**\n",
    "\n",
    "We start our modeling by splitting the dataset into train and test sets in the ratio of 80:20."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5k1ELC_T9cNl"
   },
   "outputs": [],
   "source": [
    "def get_holdout_set(target, features, period=6):\n",
    "    idx = pd.IndexSlice\n",
    "    label = target.name\n",
    "    dates = np.sort(y.index.get_level_values(\"Date\").unique())\n",
    "    cv_start, cv_end = dates[0], dates[-period - 2]\n",
    "    holdout_start, holdout_end = dates[-period - 1], dates[-1]\n",
    "\n",
    "    df = features.join(target.to_frame())\n",
    "    train = df.loc[idx[:, cv_start:cv_end], :]\n",
    "    y_train, X_train = train[label], train.drop(label, axis=1)\n",
    "\n",
    "    test = df.loc[idx[:, holdout_start:holdout_end], :]\n",
    "    y_test, X_test = test[label], test.drop(label, axis=1)\n",
    "    return y_train, X_train, y_test, X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4y68Feh3AS7U"
   },
   "outputs": [],
   "source": [
    "subset_validation = BTC_Data[1301:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zMDtl3A4HwWj",
    "outputId": "fa4fe55f-a3c4-4eaa-af51-44d2907040ac"
   },
   "outputs": [],
   "source": [
    "subset_validation.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n7aTAW5fGmdQ"
   },
   "outputs": [],
   "source": [
    "# split out validation dataset for the end\n",
    "subset_dataset = BTC_Data[:1300]\n",
    "y = subset_dataset[\"signal\"]\n",
    "X = subset_dataset.loc[:, BTC_Data.columns != \"signal\"]\n",
    "X.index = pd.to_datetime(X.index)\n",
    "validation_size = 0.2\n",
    "seed = 1\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=validation_size, random_state=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-kLsiJ21_HK9",
    "outputId": "cedecbae-b196-47c9-91e0-104c7069a253"
   },
   "outputs": [],
   "source": [
    "subset_dataset.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tTghy90jPxcv"
   },
   "source": [
    "We create a **validation** dataset that consists of the remaining data we did not pick in the subset dataset. This validation dataset will only be used in backtesting our models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GkXeoKejJG06"
   },
   "outputs": [],
   "source": [
    "subset_validation = BTC_Data[1300:]\n",
    "y_validation = subset_validation[\"signal\"]\n",
    "X_validation = subset_validation.loc[:, BTC_Data.columns != \"signal\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BBifXOMXPQ7A",
    "outputId": "7e51ac4b-2785-4b0e-9807-9bc8410f9c8d"
   },
   "outputs": [],
   "source": [
    "X_validation.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_9PrjqiD6TGX"
   },
   "source": [
    "### **5.1 Baseline Classifier**\n",
    "\n",
    "As discussed in the previous module, it is important to train a baseline classifier that will be used as a baseline to compare with the real classifiers we will use for this task. We will use `sklearn` [DummyClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.dummy.DummyClassifier.html) as our baseline classifier and choose `strategy=stratified` that predicts the most frequent class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H8BMsMXyQDx5"
   },
   "source": [
    "We start by defining our evaluation metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WDtBudyzGmfj"
   },
   "outputs": [],
   "source": [
    "# test options for classification\n",
    "num_folds = 10\n",
    "seed = 42\n",
    "scoring = \"accuracy\"\n",
    "metrics = {\n",
    "    \"balanced_accuracy\": \"Accuracy\",\n",
    "    \"roc_auc\": \"AUC\",\n",
    "    \"neg_log_loss\": \"Log Loss\",\n",
    "    \"f1_weighted\": \"F1\",\n",
    "    \"precision_weighted\": \"Precision\",\n",
    "    \"recall_weighted\": \"Recall\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "thusJU02905E"
   },
   "source": [
    "We define a cross-validation function that will help us evaluate different algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J9jthyJm97BY"
   },
   "outputs": [],
   "source": [
    "def run_cv(clf, X=X, y=y, metrics=metrics, cv=10, fit_params=None, n_jobs=-1):\n",
    "    start = time()\n",
    "    scores = cross_validate(\n",
    "        estimator=clf,\n",
    "        X=X,\n",
    "        y=y,\n",
    "        scoring=list(metrics.keys()),\n",
    "        cv=cv,\n",
    "        return_train_score=True,\n",
    "        n_jobs=n_jobs,\n",
    "        verbose=1,\n",
    "        fit_params=fit_params,\n",
    "    )\n",
    "    duration = time() - start\n",
    "    return scores, duration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oH_ZWG17USfc"
   },
   "source": [
    "We also define a function that will help us manipulate the cross-validation output and plot them as will be seen in examples applied in this lesson."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sqna0BlKBQD-"
   },
   "outputs": [],
   "source": [
    "def stack_results(scores):\n",
    "    columns = pd.MultiIndex.from_tuples(\n",
    "        [tuple(m.split(\"_\", 1)) for m in scores.keys()], names=[\"Dataset\", \"Metric\"]\n",
    "    )\n",
    "    data = np.array(list(scores.values())).T\n",
    "    df = pd.DataFrame(data=data, columns=columns).iloc[:, 2:]\n",
    "    results = pd.melt(df, value_name=\"Value\")\n",
    "    results.Metric = results.Metric.apply(lambda x: metrics.get(x))\n",
    "    results.Dataset = results.Dataset.str.capitalize()\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZezsGTauUgyh"
   },
   "source": [
    "We finally define a plot function that will display the metrics of our models as box plots so as to allow us to visualize the distribution of the model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u9LYpGKg_Y-r"
   },
   "outputs": [],
   "source": [
    "def plot_result(df, model=None, fname=None):\n",
    "    m = list(metrics.values())\n",
    "    g = sns.catplot(\n",
    "        x=\"Dataset\",\n",
    "        y=\"Value\",\n",
    "        hue=\"Dataset\",\n",
    "        col=\"Metric\",\n",
    "        data=df,\n",
    "        col_order=m,\n",
    "        order=[\"Train\", \"Test\"],\n",
    "        kind=\"box\",\n",
    "        col_wrap=3,\n",
    "        sharey=False,\n",
    "        height=4,\n",
    "        aspect=1.2,\n",
    "    )\n",
    "    df = df.groupby([\"Metric\", \"Dataset\"]).Value.mean().unstack().loc[m]\n",
    "    for i, ax in enumerate(g.axes.flat):\n",
    "        s = f\"Train: {df.loc[m[i], 'Train']:>7.4f}\\nTest:  {df.loc[m[i], 'Test'] :>7.4f}\"\n",
    "        ax.text(\n",
    "            0.05,\n",
    "            0.85,\n",
    "            s,\n",
    "            fontsize=10,\n",
    "            transform=ax.transAxes,\n",
    "            bbox=dict(facecolor=\"white\", edgecolor=\"grey\", boxstyle=\"round,pad=0.5\"),\n",
    "        )\n",
    "    g.fig.suptitle(model, fontsize=16)\n",
    "    g.fig.subplots_adjust(top=0.9)\n",
    "    if fname:\n",
    "        g.savefig(fname, dpi=300);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gSVgjTxvU47l"
   },
   "source": [
    "We now start by defining the dummy classifier as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EvMtA2eZ_j8c"
   },
   "outputs": [],
   "source": [
    "dummy_clf = DummyClassifier(strategy=\"stratified\", random_state=42)\n",
    "algo = \"dummy_clf\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aBYVCLhmU-5P"
   },
   "source": [
    "We run the dummy classifier using cross-validation with the defined metrics used to measure model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e4wbFiKy_sR_",
    "outputId": "f2061b34-270d-4ee8-dd23-17c2623e6f9a"
   },
   "outputs": [],
   "source": [
    "fname = f\"{algo}.joblib\"\n",
    "\n",
    "dummy_cv_result, run_time_algo = run_cv(dummy_clf)\n",
    "joblib.dump(dummy_cv_result, fname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Btg3ZuubVTsW"
   },
   "source": [
    "We can now create a table with the model performance on each metric as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 269
    },
    "id": "hLZelvHz_3Hl",
    "outputId": "b5084962-e08d-423a-ca69-89a3b1f49461"
   },
   "outputs": [],
   "source": [
    "dummy_result = stack_results(dummy_cv_result)\n",
    "dummy_result.groupby([\"Metric\", \"Dataset\"]).Value.mean().unstack()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mCfFV0DLVb3Z"
   },
   "source": [
    "Clearly, the model performance is kind of guess work as the model is half-right nearly all the time with its model metrics showing a very na√Øve model, as we expected. This performance will act as our baseline, and when building a model, we strive to get a model that outperforms the dummy classifier. In the next cell, we visualize the above metrics using box plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 526
    },
    "id": "_WzF-uhjAAmq",
    "outputId": "9a814599-dd58-4413-8892-d23df91f3d3b"
   },
   "outputs": [],
   "source": [
    "plot_result(dummy_result, model=\"Dummy Classifier\")\n",
    "plt.suptitle(\n",
    "    \"Fig. 5: Dummy Classifier Metrics\", fontweight=\"bold\", horizontalalignment=\"right\"\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1sNu8iKIQYUo"
   },
   "source": [
    "We can now starting searching for better models that will be used to beat the dummy classifier.\n",
    "\n",
    "### **5.2 Defining the Classification Algorithms**\n",
    "\n",
    "We start by defining several models that will be evaluated and we select one of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UTj058SPGmiN"
   },
   "outputs": [],
   "source": [
    "# spot check the algorithms\n",
    "models = []\n",
    "models.append((\"LR\", LogisticRegression(n_jobs=-1)))\n",
    "models.append((\"LDA\", LinearDiscriminantAnalysis()))\n",
    "models.append((\"KNN\", KNeighborsClassifier()))\n",
    "models.append((\"CART\", DecisionTreeClassifier()))\n",
    "models.append((\"NB\", GaussianNB()))\n",
    "# Neural Network\n",
    "models.append((\"NN\", MLPClassifier()))\n",
    "# Ensemble Models\n",
    "# Boosting methods\n",
    "models.append((\"AB\", AdaBoostClassifier()))\n",
    "models.append((\"GBM\", GradientBoostingClassifier()))\n",
    "# Bagging methods\n",
    "models.append((\"RF\", RandomForestClassifier(n_jobs=-1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xX9WKFH3dvia"
   },
   "source": [
    "We now evaluate these models' performance using `kFold` cross-validation and record their mean and variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WrFC_fpAGmkp",
    "outputId": "174c3333-2509-4d72-e410-568c038eb7e6"
   },
   "outputs": [],
   "source": [
    "results = []\n",
    "names = []\n",
    "for name, model in models:\n",
    "    kfold = KFold(n_splits=num_folds)\n",
    "    cv_results = cross_val_score(model, X_train, y_train, cv=kfold, scoring=scoring)\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
    "    print(msg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sKf-GxQad2aL"
   },
   "source": [
    "Looking at the outputs recorded above, Random Forest Classifier outperforms the other models, and we select it as our preferred model. We can also visualize the performance of the algorithms in a box plot as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 543
    },
    "id": "rZZatbkLGmnG",
    "outputId": "c68d5a92-cb66-40e5-bf7d-772b1e57308f"
   },
   "outputs": [],
   "source": [
    "# compare algorithms\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "plt.boxplot(results)\n",
    "ax.set_xticklabels(names)\n",
    "fig.set_size_inches(15, 8)\n",
    "plt.suptitle(\n",
    "    \"Fig. 6: Algorithm Comparison\", fontweight=\"bold\", horizontalalignment=\"right\"\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ixf2BZ7VeBEp"
   },
   "source": [
    "## **6. Hyperparameter Tuning**\n",
    "\n",
    "Since random forest was our best performer, we seek to tune its hyperparameters to improve the performance even further.\n",
    "\n",
    "### **6.1 Grid Search**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vfjIoVkVGmpn",
    "outputId": "a9d56c5b-083f-49a7-d414-ea90ef880638"
   },
   "outputs": [],
   "source": [
    "# Grid Search: Random Forest Classifier\n",
    "\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "rescaledX = scaler.transform(X_train)\n",
    "n_estimators = [20, 80]\n",
    "max_depth = [5, 10]\n",
    "criterion = [\"gini\", \"entropy\"]\n",
    "param_grid = dict(n_estimators=n_estimators, max_depth=max_depth, criterion=criterion)\n",
    "model = RandomForestClassifier(n_jobs=-1)\n",
    "kfold = KFold(n_splits=num_folds)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, scoring=scoring, cv=kfold)\n",
    "grid_result = grid.fit(rescaledX, y_train)\n",
    "\n",
    "# Print Results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_[\"mean_test_score\"]\n",
    "stds = grid_result.cv_results_[\"std_test_score\"]\n",
    "params = grid_result.cv_results_[\"params\"]\n",
    "ranks = grid_result.cv_results_[\"rank_test_score\"]\n",
    "for mean, stdev, param, rank in zip(means, stds, params, ranks):\n",
    "    print(\"#%d %f (%f) with: %r\" % (rank, mean, stdev, param))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eulCeevhYndw"
   },
   "source": [
    "We can now fix the best hyperparameters to our model and use it to compare with the dummy classifier. We repeat the same steps as in the dummy classifier problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UxK9qOcYGmtA"
   },
   "outputs": [],
   "source": [
    "# prepare model\n",
    "model = RandomForestClassifier(\n",
    "    criterion=\"gini\", n_estimators=80, max_depth=10, n_jobs=-1\n",
    ")  # `rbf` is default kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9Ga6cjizC4e8"
   },
   "outputs": [],
   "source": [
    "algo_forest = \"random_forest\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BdaY-P9JDNxV",
    "outputId": "06a2ef66-2b71-47f1-9ddb-1e4ce18706fb"
   },
   "outputs": [],
   "source": [
    "fname = f\"{algo_forest}.joblib\"\n",
    "\n",
    "random_forest_cv_result, run_time_algo_forest = run_cv(model)\n",
    "joblib.dump(random_forest_cv_result, fname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "stUh8dkpY7Np"
   },
   "source": [
    "We can now display the model performance table below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 269
    },
    "id": "8SXm-RvWDgAm",
    "outputId": "27bd9ce6-ae3e-44cf-bf42-d851272d73d2"
   },
   "outputs": [],
   "source": [
    "rf_result = stack_results(random_forest_cv_result)\n",
    "rf_result.groupby([\"Metric\", \"Dataset\"]).Value.mean().unstack()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pNetOsliZEWO"
   },
   "source": [
    "The cell below displays the above metrics as box plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 526
    },
    "id": "xFNMga0gD83P",
    "outputId": "890ee4c3-78fa-4115-e8f4-34cdcfc0400b"
   },
   "outputs": [],
   "source": [
    "plot_result(rf_result, model=\"Random Forest Classifier\")\n",
    "plt.suptitle(\n",
    "    \"Fig. 7: Random Forest Classifier Metrics\",\n",
    "    fontweight=\"bold\",\n",
    "    horizontalalignment=\"right\",\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aoLrZ3HFZcH3"
   },
   "source": [
    "Clearly, random forest classifier outperforms the dummy classifier by far, but we seem to face a problem of overfitting. In the prediction task, we would like to look at ways of mitigating this. The table below shows a comparison of the random forest classifier and the dummy classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 112
    },
    "id": "nzfMTFb-FFqi",
    "outputId": "26ad726a-8c17-4048-c888-affc74f7e938"
   },
   "outputs": [],
   "source": [
    "results = {\n",
    "    \"Baseline\": dummy_result,\n",
    "    \"Random Forest\": rf_result,\n",
    "}\n",
    "df = pd.DataFrame()\n",
    "for model, result in results.items():\n",
    "    df = pd.concat(\n",
    "        [\n",
    "            df,\n",
    "            result.groupby([\"Metric\", \"Dataset\"])\n",
    "            .Value.mean()\n",
    "            .unstack()[\"Test\"]\n",
    "            .to_frame(model),\n",
    "        ],\n",
    "        axis=1,\n",
    "    )\n",
    "\n",
    "df.T.sort_values(\"AUC\", ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rAX6LvabZ78R"
   },
   "source": [
    "Having settled on random forest, we can now train it on the data and analyze its performance on the holdout dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Wh84Bt4iGmzH",
    "outputId": "ebcb828a-6128-457d-8eb2-d54eeab164d3"
   },
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(\n",
    "    criterion=\"gini\", n_estimators=80, max_depth=10, n_jobs=-1\n",
    ")\n",
    "model.fit(X_train, y_train)\n",
    "# estimate accuracy on validation set\n",
    "predictions = model.predict(X_test)\n",
    "print(accuracy_score(y_test, predictions))\n",
    "print(confusion_matrix(y_test, predictions))\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t6gavJsAaNfT"
   },
   "source": [
    "The model shows a better prediction potential on the holdout dataset with performance being upwards of $94\\%$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b4pqvF04coz3"
   },
   "source": [
    "To evaluate the model's performance, we can draw the confusion matrix that allows us to visualize the models' recall, specificity, accuracy, and precision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 314
    },
    "id": "3wRDGSlLJZNP",
    "outputId": "3c757e09-375c-4ea3-b4bd-cca66932c2c7"
   },
   "outputs": [],
   "source": [
    "df_cm = pd.DataFrame(\n",
    "    confusion_matrix(y_test, predictions),\n",
    "    columns=np.unique(y_test),\n",
    "    index=np.unique(y_test),\n",
    ")\n",
    "df_cm.index.name = \"Actual\"\n",
    "df_cm.columns.name = \"Predicted\"\n",
    "sns.heatmap(df_cm, cmap=\"Blues\", annot=True, annot_kws={\"size\": 16})  # font sizes\n",
    "plt.suptitle(\"Fig. 8: Confusion Matrix\", fontweight=\"bold\", horizontalalignment=\"right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rmdboIt0cB3U"
   },
   "source": [
    "We determine the variables with more predictive powers as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 560
    },
    "id": "zfFx29H3JZQr",
    "outputId": "4ffecd2c-f125-4655-a89e-c3804428c9ab"
   },
   "outputs": [],
   "source": [
    "Importance = pd.DataFrame(\n",
    "    {\"Importance\": model.feature_importances_ * 100}, index=X.columns\n",
    ")\n",
    "Importance.sort_values(\"Importance\", axis=0, ascending=True).plot(\n",
    "    kind=\"barh\", color=\"r\", figsize=(12, 8)\n",
    ")\n",
    "plt.xlabel(\"Variable Importance\")\n",
    "plt.suptitle(\n",
    "    \"Fig. 9: Variable Importance\", fontweight=\"bold\", horizontalalignment=\"right\"\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TC913UUHfHYS"
   },
   "source": [
    "### **6.2 Bayesian Optimization**\n",
    "\n",
    "The Bayesian optimization process uses the Gaussian process to model the mean and variance of our objective function. In every iteration, it tries different combinations of hyperparameter values and builds a new model by using the model's past information. This has the advantage of reducing training time to achieve better results.\n",
    "\n",
    "We start by defining the stratified `kFold` function that will be used to perform cross-validation on the training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RiibJ8WSNyH8"
   },
   "outputs": [],
   "source": [
    "def stratified_kfold_score(clf, X_train, y_train, n_fold):\n",
    "    X, y = X_train.values, y_train.values\n",
    "    strat_kfold = StratifiedKFold(n_splits=n_fold, shuffle=True, random_state=1)\n",
    "    accuracy_list = []\n",
    "\n",
    "    for train_index, test_index in strat_kfold.split(X, y):\n",
    "        x_train_fold, x_test_fold = X[train_index], X[test_index]\n",
    "        y_train_fold, y_test_fold = y[train_index], y[test_index]\n",
    "        clf.fit(x_train_fold, y_train_fold)\n",
    "        preds = clf.predict(x_test_fold)\n",
    "        accuracy_test = accuracy_score(preds, y_test_fold)\n",
    "        accuracy_list.append(accuracy_test)\n",
    "\n",
    "    return np.array(accuracy_list).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9RR7d3G6bP19"
   },
   "source": [
    "We also define a function with the model hyperparameters we would like to tune, that is, `max_samples`, `max_features` and `n_estimators`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sQMmBnYmNyKd"
   },
   "outputs": [],
   "source": [
    "def bo_params_rf(max_samples, n_estimators, max_features):\n",
    "\n",
    "    params = {\n",
    "        \"max_samples\": max_samples,\n",
    "        \"max_features\": max_features,\n",
    "        \"n_estimators\": int(n_estimators),\n",
    "    }\n",
    "    clf = RandomForestClassifier(\n",
    "        max_samples=params[\"max_samples\"],\n",
    "        max_features=params[\"max_features\"],\n",
    "        n_estimators=params[\"n_estimators\"],\n",
    "    )\n",
    "    score = stratified_kfold_score(clf, X_train, y_train, 5)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2P1vrs_9b0Nm"
   },
   "source": [
    "In the cell that follows, we give a range of hyperparameter space that the Bayesian optimization will search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n3GojpHJNyM5"
   },
   "outputs": [],
   "source": [
    "rf_bo = BayesianOptimization(\n",
    "    bo_params_rf,\n",
    "    {\"max_samples\": (0.2, 1), \"max_features\": (0.5, 1), \"n_estimators\": (50, 200)},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aM1dTBkJcjRQ"
   },
   "source": [
    "We can now apply Bayesian optimization to search through the hyperparameter space and output the results at each iteration. The cell below outputs the performance for each hyperparameter combination it finds and labels in blue the combination with a higher score than the previous combinations it has already selected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "M3mCr6fTNyPr",
    "outputId": "ee2f549d-a342-4d33-8904-aa18e12ec8c6"
   },
   "outputs": [],
   "source": [
    "results = rf_bo.maximize(n_iter=200, init_points=20, acq=\"ei\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pTy8jMi0d-js"
   },
   "source": [
    "We can now display the best hyperparameters that have been encountered by Bayesian optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RxMczH2RNyTO",
    "outputId": "6675693f-6205-43c0-c969-24c6a3c885c4"
   },
   "outputs": [],
   "source": [
    "params = rf_bo.max[\"params\"]\n",
    "params[\"n_estimators\"] = int(params[\"n_estimators\"])\n",
    "print(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "beSD8OneeLOu"
   },
   "source": [
    "We can now fix these hyperparameters on our model as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9gVgiUUMOP_u"
   },
   "outputs": [],
   "source": [
    "rf_v1 = RandomForestClassifier(\n",
    "    max_samples=params[\"max_samples\"],\n",
    "    max_features=params[\"max_features\"],\n",
    "    n_estimators=params[\"n_estimators\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3aVoNKs0eRxZ"
   },
   "source": [
    "We now use our training dataset to train the above model having the best selected hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ry17RoxTOQDT",
    "outputId": "6081c07c-20f9-40ec-f4a1-e6b08dd2dc00"
   },
   "outputs": [],
   "source": [
    "rf_v1.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D9KVB2ETeonX"
   },
   "source": [
    "From the model we have trained above, we use that to predict on the holdout dataset and evaluate the model performance using the classification report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s7yPKsK7OmM1"
   },
   "outputs": [],
   "source": [
    "preds = rf_v1.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qDVvI047Ovaj",
    "outputId": "31cd9fb5-7486-47bd-aae3-d295d36f6845"
   },
   "outputs": [],
   "source": [
    "print(classification_report(preds, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ss9Qb5B7fDWI"
   },
   "source": [
    "The classification report above shows that the model correctly predicts the signals with a high precision. We can print out the values of precision score, recall score, and f1 score to better shed light on the classification report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nWmYBNX7O3N8",
    "outputId": "e85d898c-328d-46fa-8de7-63ccef55aaeb"
   },
   "outputs": [],
   "source": [
    "print(\"Precision:{}\".format(precision_score(preds, y_test)))\n",
    "print(\"Recall:{}\".format(recall_score(preds, y_test)))\n",
    "print(\"F1 Score:{}\".format((f1_score(preds, y_test))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lXpUYUpEfmmJ"
   },
   "source": [
    "As alluded, we get high performance on the classification report. Can we improve the model performance? Let's implement the stratified `kFold` validation below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "H_3Gvy9sO3Qk",
    "outputId": "2a247909-b36f-4a2d-e5bc-88505d291a53"
   },
   "outputs": [],
   "source": [
    "cv = StratifiedKFold(n_splits=5, random_state=123, shuffle=True)\n",
    "scores = []\n",
    "\n",
    "for (train, test), i in zip(cv.split(X_train, y_train), range(5)):\n",
    "    rf_v1.fit(X.iloc[train], y.iloc[train])\n",
    "    preds = rf_v1.predict(X_train.iloc[test])\n",
    "    accuracy = accuracy_score(preds, y_train.iloc[test])\n",
    "    scores.append(accuracy)\n",
    "\n",
    "df_val = pd.DataFrame(scores, columns=[\"Accuracy Test\"])\n",
    "print(\n",
    "    \"KFold validation mean accuracy on test set : {}\".format(\n",
    "        df_val[\"Accuracy Test\"].mean()\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S_ldePGCgV-r"
   },
   "source": [
    "The accuracy on the test dataset shows a comparable result with what we have seen so far."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PFSyTaW6euH_"
   },
   "source": [
    "### **7. Backtesting**\n",
    "\n",
    "We now want to see how our trading strategy would perform on historical data, and this is possible with the help of backtesting. Backtesting allows us to simulate how we would have performed in the past without using any financial capital. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 979
    },
    "id": "uhJ9ZprBO3WR",
    "outputId": "22e45c3c-09c8-4077-8a26-4e77da289f7d"
   },
   "outputs": [],
   "source": [
    "# Create column for Strategy Returns by multiplying the daily returns by the position that was held at close\n",
    "# of business the previous day\n",
    "backtestdata = pd.DataFrame(index=X_validation.index)\n",
    "validation_prediction = rf_v1.predict(X_validation)\n",
    "backtestdata[\"signal_pred\"] = validation_prediction\n",
    "backtestdata[\"signal_actual\"] = y_validation\n",
    "backtestdata[\"Market Returns\"] = X_validation[\"Close\"].pct_change()\n",
    "backtestdata[\"Actual Returns\"] = backtestdata[\"Market Returns\"] * backtestdata[\n",
    "    \"signal_actual\"\n",
    "].shift(1)\n",
    "backtestdata[\"Strategy Returns\"] = backtestdata[\"Market Returns\"] * backtestdata[\n",
    "    \"signal_pred\"\n",
    "].shift(1)\n",
    "# backtestdata=backtestdata.reset_index()\n",
    "backtestdata.head()\n",
    "\n",
    "fig, axs = plt.subplots(2, figsize=(15, 15))\n",
    "fig.suptitle(\"Vertically stacked subplots\")\n",
    "axs[0].plot(backtestdata[\"Strategy Returns\"])\n",
    "axs[0].set_title(\"Strategy Returns\")\n",
    "axs[1].plot(backtestdata[\"Actual Returns\"])\n",
    "axs[1].set_title(\"Bitcoin Daily Returns\")\n",
    "\n",
    "for ax in axs.flat:\n",
    "    ax.set(xlabel=\"Predicted Days\", ylabel=\"Returns\")\n",
    "\n",
    "# `backtestdata`[['Strategy Returns','Actual Returns']].plot()\n",
    "# `plt.title`('Cumulative Strategy Returns vs Cumulative Actual Returns')\n",
    "plt.suptitle(\n",
    "    \"Fig. 10: Strategy and Bitcoin Daily Returns Separate Graphs\",\n",
    "    fontweight=\"bold\",\n",
    "    horizontalalignment=\"right\",\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4iq4T8P_hDoZ"
   },
   "source": [
    "In the above diagrams, we visualize the strategy and Bitcoin daily returns in two separate figures. We put the above figures on the same figure below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 571
    },
    "id": "EJuBSk-MTWZW",
    "outputId": "70132e29-b541-45fd-bc00-be8c155529de"
   },
   "outputs": [],
   "source": [
    "backtestdata[[\"Strategy Returns\", \"Actual Returns\"]].plot(figsize=(15, 8))\n",
    "plt.title(\"Strategy Returns vs BITCOIN DAILY Returns chart 2\")\n",
    "plt.suptitle(\n",
    "    \"Fig. 11: Strategy and Bitcoin Daily Returns\",\n",
    "    fontweight=\"bold\",\n",
    "    horizontalalignment=\"right\",\n",
    ")\n",
    "plt.xlabel(\"Test Days\")\n",
    "plt.ylabel(\"Returns\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RaUArGKNhT00"
   },
   "source": [
    "We can clearly see that the strategy and Bitcoin daily return are identical on most test days with the exception of very few days. We can now plot the cumulative returns for both strategy returns and the Bitcoin returns to compare how we expect to perform in the near future if we applied our trading model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 521
    },
    "id": "kggpuXzm-tRY",
    "outputId": "be375030-ddbc-4d25-ef60-ab66167a0ffc"
   },
   "outputs": [],
   "source": [
    "backtestdata[[\"Strategy Returns\", \"Actual Returns\"]].cumsum().plot(figsize=(15, 8))\n",
    "plt.xlabel(\"Test Days\")\n",
    "plt.ylabel(\"Cumulative Returns\")\n",
    "plt.suptitle(\n",
    "    \"Fig. 12: Cumulative Strategy Returns vs Cumulative BITCOIN  Returns\",\n",
    "    fontweight=\"bold\",\n",
    "    horizontalalignment=\"right\",\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3ybKRBzRuBvj"
   },
   "source": [
    "## **7. Conclusion**\n",
    "\n",
    "In this lesson, we have learned how to apply Bayesian optimization and grid search on our model to improve performance. We also saw how to use baseline models as a reference to the models we will use to predict the buy or sell signals. We anticipate that more could be done to better improve the model, and we ask the students to explore more.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7-X-AarjuF9Y"
   },
   "source": [
    "**References**\n",
    "\n",
    "1. Snoek, Jasper, et al. \"Practical Bayesian Optimization of Machine Learning Algorithms.\" *Advances in Neural Information Processing Systems*, vol. 25, 2012.\n",
    "2. Shalini, Talwar, Shah Pranav, and Shah Utkarsh. \"Picking buy-sell signals: A practitioner‚Äôs perspective on key technical indicators for selected Indian firms.\" Studies in Business & Economics 14.3 (2019).\n",
    "3. Bergstra, James, et al. \"Algorithms for Hyper-parameter Optimization.\" *Advances in Neural Information Processing Systems*, vol. 24, 2011. https://proceedings.neurips.cc/paper/2011/file/86e8f7ab32cfd12577bc2619bc635690-Paper.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "---\n",
    "Copyright 2023 WorldQuant University. This\n",
    "content is licensed solely for personal use. Redistribution or\n",
    "publication of this material is strictly prohibited.\n"
   ]
  }
 ],
 "metadata": {
  "execution": {
   "timeout": 3000
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
