{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "ojFr1lDqtO-A"
   },
   "source": [
    "\n",
    "## MACHINE LEARNING IN FINANCE\n",
    "MODULE 5 | LESSON 4\n",
    "\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "zSLS-GqxtWB5"
   },
   "source": [
    "# **NEURAL NETWORKS IN FINANCE**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "it2RrrWEtdky"
   },
   "source": [
    "|  |  |\n",
    "|:---|:---|\n",
    "|**Reading Time** |  25 minutes |\n",
    "|**Prior Knowledge** | Neural Network architecture, Economic data  |\n",
    "|**Keywords** |Keras, TensorFlow, Layers, Mean Square Error, Mean Absolute Error  |\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "TPzpLVqBuIXC"
   },
   "source": [
    "*The previous lesson covered the workings and architecture of a neural network. In this lesson, we put this into practice by exposing the reader to additional data preparation and model compilation.*\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "JLx6jzyG4BU-"
   },
   "source": [
    "## **1. Predictive Problem**\n",
    "\n",
    "In this lesson, we will look at predicting monthly returns on the Dow Jones Industrial (DJI) Futures, specifically the Mini DJI Futures with ticker YM=F. The predictors we use are economic indicators from the FRED economic database. You may be familiar with this site from the Financial Data course. We consider five economic indicators, namely:\n",
    "\n",
    "\n",
    "1.   Average hourly earnings of all employees \n",
    "2.   All Employees Manufacturing \n",
    "3.   Producer Price Index by Industry\n",
    "4.   Durable goods New Orders\n",
    "5.   Manufacturers' New Orders: Total Manufacturing\n",
    "\n",
    "Economic data can be found on this website https://fred.stlouisfed.org/ and made available using an API key, which you can obtain by signing up with an account. Let's begin by importing the Economic data using the `pandas_datareader` package.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "HK0UqF1m7vvn"
   },
   "source": [
    "## **2. Getting the Data**\n",
    "\n",
    "We import the `pandas_datareader` below as well as pandas since we will be working with DataFrames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "id": "Fgu68R_ut7fn"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pandas_datareader as pdr  # Access FRED"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "QJ_pFYsz7rDM"
   },
   "source": [
    "Now that we've imported the necessary package required to obtain the data from FRED, we specify the API key that we obtained after creating an account. It is quite an easy and quick process to obtain an API key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "id": "lDBCt8n3ubkd"
   },
   "outputs": [],
   "source": [
    "# extract api key: put your key in between the angle brackets < >\n",
    "# myKey = \"xxx\"\n",
    "fred_api_key = \"<ENTER YOUR API KEY>\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "wih3IMbt8f-v"
   },
   "source": [
    "We'll use this function created below called *get_fred_data*, which makes importing the data very simple. The input parameters are the list of economic indicator keywords and the date range of the data, i.e., start and end date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "id": "j1BfY3OyvC42"
   },
   "outputs": [],
   "source": [
    "# Using code from FRED API: Get US Economic Data using Python\n",
    "\n",
    "\n",
    "def get_fred_data(param_list, start_date, end_date):\n",
    "    df = pdr.DataReader(param_list, \"fred\", start_date, end_date)\n",
    "    return df.reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "NBLesq-S9ETH"
   },
   "source": [
    "Below is the list of the economic indicator keywords for the five predictors. These keywords are obtained from the FRED website. See below encapsulated in red in Figure 1 as an example.\n",
    "\n",
    "**Figure 1: Keyword for Manufacturers' New Orders - Total Manufacturing.**\n",
    "\n",
    "![](https://drive.google.com/uc?export=view&id=1Cvyx_Le72AbkMkXecnFmAndxb4V5FwIW)\n",
    "\n",
    "A list of indicators used and considered is shown below in the next cell. We import the data and take a glimpse using the pandas tail(10) command to view the last 10 records. Note that we consider monthly data and take data from Jan. 2000 to Apr. 2022 inclusively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 412
    },
    "deletable": false,
    "id": "gCemDLBmvHet",
    "outputId": "1a96dd36-8a74-4aac-dc3b-018f07bee145"
   },
   "outputs": [],
   "source": [
    "# PCUOMFGOMFG :        Producer Price Index by Industry - Monthly\n",
    "# BOGZ1FL073164003Q :  Interest Rates and Price Indexes; NYSE Composite Index, Level-Quarterly\n",
    "# CES0500000003 :      Average hourly earnings of all employees\n",
    "# MANEMP:              All Employees Manufacturing\n",
    "# DGORDER:             Durable goods New Orders\n",
    "# AMTMNO:              Manufacturers' New Orders: Total Manufacturing\n",
    "# FEDFUNDS:            Fed fund rate. Lagging indicator\n",
    "\n",
    "\n",
    "series = [\"CES0500000003\", \"MANEMP\", \"PCUOMFGOMFG\", \"DGORDER\", \"AMTMNO\"]\n",
    "# get data for series\n",
    "df = get_fred_data(param_list=series, start_date=\"2000-01-01\", end_date=\"2022-05-03\")\n",
    "df.set_index(\"DATE\", drop=True, inplace=True)\n",
    "print(df.shape)\n",
    "df.tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "Xtzt__wU_RJJ"
   },
   "source": [
    "So now that we have our predictors, let's get the target variable, which is the adjusted close price for the Mini DJI futures. We get this data using the yahoo finance (*yfinance*) library. We import monthly data in keeping with the same timeframe as our predictors for the same time period. We have imported Open, High, Low, Close, Adj Close and Volume; however, we consider only the Adj Close that takes into account corporate actions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 429
    },
    "deletable": false,
    "id": "0UPKwFeJ2_gk",
    "outputId": "24dde6fd-8d45-447f-96cd-951f0e5e1dd0"
   },
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "\n",
    "# Mini DJI Futures ticker is YM=F\n",
    "data = yf.download(tickers=\"YM=F\", start=\"2000-01-01\", end=\"2022-05-03\", interval=\"1mo\")\n",
    "# Print data\n",
    "print(data.shape)\n",
    "data.tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "WsoYGLmsA0qK"
   },
   "source": [
    "We have our predictors and target variable in different DataFrames; however, they can be joined/merged using the common date index column. We do this using the pandas merge command. It is also necessary to look at missing values or Nulls in the dataset. This could be for unavailability of data on those dates. Fortunately, there are 39 rows missing for the Average hourly earnings of all employees (CES0500000003) column, which isn't too many. We adopt the simplest approach of dropping them since there aren't too many missing values. We are left with 166 rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "# Make time zones non-timezone aware so as to allow the join\n",
    "df.index = df.index.tz_localize(None)\n",
    "data.index = data.index.tz_localize(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "deletable": false,
    "id": "_C49Mutz9fvI",
    "outputId": "91d2e0c3-b2ad-41ce-9295-079f24458007"
   },
   "outputs": [],
   "source": [
    "df2predict = pd.merge(df, data[\"Adj Close\"], left_index=True, right_index=True)\n",
    "print(df2predict.tail())\n",
    "print(len(df2predict))\n",
    "df2predict.isnull().sum()\n",
    "df2predict = df2predict.dropna()\n",
    "\n",
    "print(\"Print rows remaining after removed missing values {}\".format(len(df2predict)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "JuM0D0MfCwLo"
   },
   "source": [
    "We've done a lot of work to put this dataset together, so let's store it as a csv so we can easily read it in when we want to work with it. Specify the path to store it and the name; in my case, I called it `DJI_FuturesPredict.csv`. When we want to read the data in, we just use the pandas `read_csv` command as in the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "id": "sqNjJU09SEwT"
   },
   "outputs": [],
   "source": [
    "# Store to csv\n",
    "path2copy = \"../../data\"\n",
    "df2predict.to_csv(path2copy + \"/DJI_FuturesPredict.csv\", index=True, index_label=\"Date\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "deletable": false,
    "id": "98lK1OauUWac",
    "outputId": "d6e5a347-e389-4da3-9024-c684ab4dbc15"
   },
   "outputs": [],
   "source": [
    "# read in pre-stored data\n",
    "\n",
    "df2predict = pd.read_csv(path2copy + \"/DJI_FuturesPredict.csv\")\n",
    "df2predict.set_index(\"Date\", drop=True, inplace=True)\n",
    "\n",
    "# Quick check that the data looks familiar.\n",
    "df2predict.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "b5C2-R4LEOek"
   },
   "source": [
    "## **3. Data Analysis and Preparation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "8O99wh98KHBc"
   },
   "source": [
    "Neural Networks are sensitive to the scale of the features for accuracy as well as the speed of training. There is no single best way to scale the data as we could use percentage change, min max, or standard scaling, among other suggestions, and it depends on the problem. In this example, we use the min max scaling method from `sklearn`. The formula for this is:\n",
    "$$\n",
    "\\begin{align}\n",
    "x_{scaled} = \\frac{x - x_{min}}{x_{max}-x_{min}}\n",
    "\\end{align}\n",
    "$$\n",
    "where,\n",
    "\n",
    "*   $x_{min}$ = minimum feature value\n",
    "*   $x_{max}$ = maximum feature value\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "deletable": false,
    "id": "IfVDA7jCJvVz",
    "outputId": "0b26e9a3-1ca0-48ba-eaa6-75869be537b7"
   },
   "outputs": [],
   "source": [
    "# Feature scaling\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# scale features\n",
    "scaler = MinMaxScaler()\n",
    "scale_model = scaler.fit(df2predict[series])\n",
    "df2predict[series] = scale_model.transform(df2predict[series])\n",
    "df2predict.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "qovjeXkhKkIY"
   },
   "source": [
    "We're interested in predicting the returns of the DJI Futures. As such, we transform the Adj Close price column to percentage returns instead. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "id": "n2RP1-33K4_A"
   },
   "outputs": [],
   "source": [
    "# Use percent change instead of actual values\n",
    "# If all columns are transformed to a % change.\n",
    "# df2predict = df2predict.pct_change()\n",
    "\n",
    "# % change for just the target column\n",
    "df2predict[\"Adj Close\"] = df2predict[\"Adj Close\"].pct_change()\n",
    "\n",
    "# Drop any missing values\n",
    "df2predict.dropna(inplace=True)\n",
    "# If a time shift is needed because of a lag.\n",
    "# `df2predict['AdjClose_shift'] = df2predict['Adj Close'].shift(-1)`\n",
    "# `df2predict.drop('Adj Close', axis=1, inplace=True)`\n",
    "\n",
    "# Glimpse of data\n",
    "df2predict.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "8eqlIdN4LNKp"
   },
   "source": [
    "It is a good idea to look at the relation of the predictors to the Adj Close price returns. We can do this visually since there aren't too many predictors considered. To avoid too much clutter in the plots and determine any time lag between the Adj Close returns and predictor, we choose a sample of points, say 3 years or 36 months. The visual below does not show strong correlations between the predictors and returns; however, the decrease in Feb. and Mar. of 2020 is experienced for most predictors as well as the returns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "id": "xvvZUhbQLG7L"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "deletable": false,
    "id": "_kbA3iRrUOXv",
    "outputId": "b4802523-bff0-4417-bcf7-5c41ae04729f"
   },
   "outputs": [],
   "source": [
    "target = \"Adj Close\"\n",
    "n_pts = 36\n",
    "\n",
    "for j in np.arange(len(series)):\n",
    "    # Check the lag\n",
    "\n",
    "    var = series[j]\n",
    "    # Define Data\n",
    "    # choose sample of points to avoid clutter in plot\n",
    "    df2plot = df2predict.iloc[len(df2predict) - n_pts : len(df2predict),]  # noQA E203\n",
    "    x = df2plot.index\n",
    "    data_1 = df2plot[var]\n",
    "    data_2 = df2plot[target]\n",
    "\n",
    "    # Create Plot\n",
    "\n",
    "    fig, ax1 = plt.subplots()\n",
    "\n",
    "    ax1.set_xlabel(\"Date\")\n",
    "    ax1.set_ylabel(var, color=\"red\")\n",
    "    ax1.plot(x, data_1, color=\"red\")\n",
    "    plt.xticks(rotation=90)  # Rotates X-Axis Ticks by 45-degrees\n",
    "    # Adding Twin Axes\n",
    "\n",
    "    ax2 = ax1.twinx()\n",
    "    ax2.plot(x, data_2, color=\"blue\")\n",
    "\n",
    "    # Add label\n",
    "\n",
    "    ax2.set_ylabel(\"Adj Close returns\", color=\"blue\")\n",
    "    ax2.tick_params(axis=\"y\", color=\"blue\")\n",
    "\n",
    "    # Show plot\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "OzkVPul4MUkH"
   },
   "source": [
    "With that, we are now ready to create our Neural Network using TensorFlow and Keras."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "rBVRmQW1Mp5K"
   },
   "source": [
    "## **4. Keras and TensorFlow**\n",
    "\n",
    "Neural networks were initially made easily in Python thanks to the Keras library made by Francois Chollet. His book is also a great resource for neural networks and deep learning (Chollet 54); however, it is not open source. \n",
    "\n",
    "Google created a library called TensorFlow (tf) that did the computations for neural networks efficiently, but it is not the most user-friendly.\n",
    "\n",
    "Google later released TensorFlow 2 that integrated the Keras API directly and promoted this interface as the default or standard interface for deep learning development on the platform.\n",
    "\n",
    "This is why we often see tf.keras used in deep learning code, which makes it much easier and faster to compile and run these models.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "deletable": false,
    "id": "iSuppCro_fyY",
    "outputId": "fbb84c63-7999-43fd-b80e-8a597a18b7cb"
   },
   "outputs": [],
   "source": [
    "# Begin creating our model by importing TensorFlow\n",
    "import tensorflow as tf\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "32WtBSPfGTXa"
   },
   "source": [
    "We now separate the data into a predictors dataset and target column into x and y respectively.<span style='color: transparent; font-size:1%'>All rights reserved WQU WorldQuant University QQQQ</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "id": "8FuqnG-DAcUJ"
   },
   "outputs": [],
   "source": [
    "X = df2predict[series].values\n",
    "y = df2predict[\"Adj Close\"].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "MSN9NhqHRnhX"
   },
   "source": [
    "We perform the necessary train/test split for our data required for predictive modeling. In our case the train/test split is 80/20 and the split is done in a time-ordered manner with recent data being the unseen dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "deletable": false,
    "id": "7QtbOvoXAwQz",
    "outputId": "7a97c65f-3b86-45ef-c76a-475ac0f56c79"
   },
   "outputs": [],
   "source": [
    "test_sz = 0.2\n",
    "train_sz = int((1 - test_sz) * len(X))\n",
    "X_train = X[:train_sz]\n",
    "y_train = y[:train_sz]\n",
    "X_test = X[train_sz:]\n",
    "y_test = y[train_sz:]\n",
    "len(X_train), len(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "C0XZjbbOSgBj"
   },
   "source": [
    "In the below cell, we will do a couple of things for the model build. We set a random seed to enable us to replicate this build at any time. We then call the various tf.keras objects to put our model together starting with *Sequential*. It is referred to as sequential because we are able to add layers to our NN one after another in sequence. In the simplest example for illustrative purposes, we have only one layer, but we will add onto it later. The *tf.keras.Dense* object should sound familiar from Module 4, Lesson 3, in that we are specifying that all edges connect to the subsequent nodes. The parameter of 1 in the Dense(1) object specifies that the output is a single continuous value, i.e., our predicted DJI Futures return.\n",
    "\n",
    "The *model.compile* command is where we specify the loss function and optimizer. In our example below, we use the mean absolute error as our loss function to gauge how far away our predictions are from actuals. For a list of supported loss functions, see (\"Keras Loss Functions\").\n",
    "\n",
    "The optimizer is SGD or stochastic gradient descent, but Adam is another popular option. The performance metric after each iteration is the mean absolute error, but we could also use mean square error. For a list of supported metrics, see (\"Keras Metrics\"). \n",
    "\n",
    "You'll notice there are specified arguments in the optimizer such as learning rate and momentum. The learning rate specifies the amount of change to the model relative to the change in error. Of course, we would naturally want our model to learn quickly; however, we should bear in mind that a large value for the learning rate could result in learning from a less than optimal set of weights too quickly, thus leading to non-convergence. This could result in an unstable learning process. A learning rate that is too small would increase the training time, possibly leading to the algorithm getting stuck. Typically, learning rate values between 0.01 to 1 are used. Momentum can speed up the training process to converge with fewer epochs. Values of momentum between 0.9 to 0.99 are often used.\n",
    "\n",
    "Epochs are the number of times the algorithm will work through the training set. The more epochs, the more time the model needs to train. With limited computing power this needs to be given some thought as the time required could increase significantly. Another reason we can't just increase epochs to as high a number as possible is that this could also lead to over-fitting. We choose 10 here for a simple illustrative purpose but will increase it later to see the change in results. Note that small learning rates would require more epochs and vice versa.\n",
    "\n",
    "The batch size is the sample size sent through at one time to be propagated through the network. The error gradient calculation is based on these samples that pass through. This would of course need to be smaller than the total number of observations in our training data. The stochastic gradient descent optimizer updates the weights based on the error gradient. Common sizes are in increments of 8. You don't want the batch size being too large a proportion of the number of training set observations. Refer to (\"Batch Size Tutorial\") for how to choose batch size. \n",
    "\n",
    "It is worth noting that the batch size and epochs work with the entire training set (80% of observations) available. All observations of the training set are sampled in sizes of the batch size and fed through the algorithm at different times.\n",
    "\n",
    "Now that we've specified the hyperparameters needed, we can compile and train the model with model.fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "deletable": false,
    "id": "OMBBl2WgShoz",
    "outputId": "1fc22799-e714-4aec-f11b-b9259c300d2b"
   },
   "outputs": [],
   "source": [
    "# Build the model\n",
    "# tf.keras: The Keras API integrated into TensorFlow 2\n",
    "\n",
    "tf.random.set_seed(42)  # first we set random seed\n",
    "model = tf.keras.Sequential([tf.keras.layers.Dense(1)])  # The output layer\n",
    "\n",
    "# We compile the model specifying loss, and optimizer.\n",
    "model.compile(\n",
    "    loss=tf.keras.losses.mae,  # Los function is MAE, mean absolute error.\n",
    "    optimizer=tf.keras.optimizers.SGD(\n",
    "        learning_rate=0.01, momentum=0.9\n",
    "    ),  # stochastic Gradient descent Optimizer\n",
    "    metrics=[\"mae\"],\n",
    ")  # performance metric is MAE\n",
    "\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=8)  # epoch and batch size specified"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "uMZ08sM_YsUi"
   },
   "source": [
    "After training our model, we can look at performance. We use the mean absolute error and mean square error since we are dealing with a continuous target variable. We see that both these metrics are below 5% and 0.3%, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "deletable": false,
    "id": "Gd3njT_qYq1b",
    "outputId": "df3424bd-13cc-4581-fc53-99a9716ca918"
   },
   "outputs": [],
   "source": [
    "# performance\n",
    "preds = model.predict(X_test)\n",
    "mae = tf.metrics.mean_absolute_error(y_true=y_test, y_pred=preds.squeeze()).numpy()\n",
    "mse = tf.metrics.mean_squared_error(y_true=y_test, y_pred=preds.squeeze()).numpy()\n",
    "mae, mse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "5AvAZ3EhZOno"
   },
   "source": [
    "Let's see if we can improve on this result with more layers and different choices of the hyperparameters, such as increasing the number of epochs. We also specify an activation function, namely the *sigmoid* function in this example. We also use the Adam optimizer function instead of the SGD. The SGD optimizer is sensitive to the learning rate, and although it can take many iterations, it can still achieve convergence relatively quickly. Adam is a popular optimizer and is used quite effectively in deep learning algorithms. Unlike SGD, Adam does not use a fixed learning rate as it adapts over iterations. \n",
    "\n",
    "We see that both metrics, MAE and MSE have decreased with 2 additional layers. Adding more layers ventures into the space of Deep Learning and helps when data is non-linear. Remember that the algorithm becomes susceptible to the vanishing gradient problem as more layers are added, especially when the activation function is the sigmoid function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "deletable": false,
    "id": "nR3C-4CwZNsk",
    "outputId": "1df9cebc-680e-48cd-907c-87d66e6a2226"
   },
   "outputs": [],
   "source": [
    "# Improve our model. More epochs, added extra layers\n",
    "\n",
    "tf.random.set_seed(42)\n",
    "model_1 = tf.keras.Sequential(\n",
    "    [\n",
    "        tf.keras.layers.Dense(\n",
    "            8, activation=\"sigmoid\", input_shape=(X_train.shape[1],)\n",
    "        ),  # added extra layer\n",
    "        tf.keras.layers.Dense(4, activation=\"sigmoid\"),  # added extra layer\n",
    "        tf.keras.layers.Dense(1),\n",
    "    ]\n",
    ")\n",
    "model_1.compile(\n",
    "    loss=tf.keras.losses.mae, optimizer=tf.keras.optimizers.Adam(), metrics=[\"mae\"]\n",
    ")\n",
    "model_1.fit(X_train, y_train, epochs=100, batch_size=8, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "deletable": false,
    "id": "1i8v1h2AZsKU",
    "outputId": "a46a01e4-9d23-4dd2-87ad-41ce5b258b6a"
   },
   "outputs": [],
   "source": [
    "# performance\n",
    "preds = model_1.predict(X_test)\n",
    "mae = tf.metrics.mean_absolute_error(y_true=y_test, y_pred=preds.squeeze()).numpy()\n",
    "mse = tf.metrics.mean_squared_error(y_true=y_test, y_pred=preds.squeeze()).numpy()\n",
    "mae, mse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "6xh4HP91uhsj"
   },
   "source": [
    "## **5. Conclusion**\n",
    "In this lesson, we applied a neural network to predicting the monthly returns of the DJI Futures. We used economic indicators from FRED as predictors and explored ways to import and format this data for a predictive analytics scenario. In setting up the neural network, we discussed several hyperparameters required to compile the network and added more layers in our last attempt. This addition of more layers is necessary when creating a deep learning model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "F7vmlGS9unb8"
   },
   "source": [
    "**References**\n",
    "\n",
    "- Chollet, Francois. *Deep Learning with Python*. Manning, 2017.\n",
    "\n",
    "- \"Keras Loss Functions.\" Keras Loss Functions List, www.tensorflow.org/api_docs/python/tf/keras/losses. Accessed 18 June 2022.\n",
    "\n",
    "- \"Keras Metrics.\" Keras Metrics List, www.tensorflow.org/api_docs/python/tf/keras/metrics. Accessed 18 June 2022.\n",
    "\n",
    "- \"Batch Size Tutorial.\" Batch Size Tutorial, www.machinelearningmastery.com/how-to-control-the-speed-and-stability-of-training-neural-networks-with-gradient-descent-batch-size. Accessed 18 June 2022.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "---\n",
    "Copyright 2024 WorldQuant University. This\n",
    "content is licensed solely for personal use. Redistribution or\n",
    "publication of this material is strictly prohibited.\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
