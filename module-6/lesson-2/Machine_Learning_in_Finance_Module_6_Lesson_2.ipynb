{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ktY_2U71fJ8F",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "ktY_2U71fJ8F"
   },
   "source": [
    "\n",
    "## MACHINE LEARNING IN FINANCE\n",
    "\n",
    "MODULE 6 | LESSON 2\n",
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5jI-z4wWQdzV",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "5jI-z4wWQdzV"
   },
   "source": [
    "# **APPLICATION OF DEEP LEARNING IN PREDICTING YIELD CURVES**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aVtPMQD5QguM",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "aVtPMQD5QguM"
   },
   "source": [
    "|  |  |\n",
    "|:---|:---|\n",
    "|**Reading Time** |  100 minutes |\n",
    "|**Prior Knowledge** | Machine learning, Introduction to deep learning  |\n",
    "|**Keywords** |Yield curve, Logistic Regression, Multi-Linear Perceptron |\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fbef246",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "2fbef246"
   },
   "source": [
    "*In the previous lesson, we introduced the concept of deep learning and its applications. In this lesson, we will build on deep learning concepts by solving a real-world problem of forecasting yield curves using deep learning algorithms and comparing our results to a high-order polynomial regression.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85e72108",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "85e72108"
   },
   "source": [
    "## **1. Recap of Yield Curves**\n",
    "We can define yield curves as a graph showing interest rates (bonds) having different maturity rates. Yield curves are important in the financial world for these reasons:\n",
    "\n",
    "1. They are used as a benchmark for setting mortgage rates, and;\n",
    "2. They provide a good indicator for predicting economic growth.\n",
    "\n",
    "There are three types of yield curves:\n",
    "\n",
    "- Normal yield curve\n",
    "- Inverted yield curve\n",
    "- Flat yield curve\n",
    "\n",
    "We will review each one of them below.\n",
    "\n",
    "### **1.1 Normal Yield Curve**\n",
    "\n",
    "The graph of a normal yield curve shows an upward trajectory that implies longer maturity date bonds will pay more in interest (have higher yield) as compared to shorter maturity date bonds.\n",
    "\n",
    "A normal yield curve can be interpreted as people having confidence that the economy will perform well in the future, and we would therefore expect the central banks to increase the interest rate in that future date. The central banks raise interest rates in response to the inflationary pressures caused by an expanding economy.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pHYjyWhFfl-e",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "pHYjyWhFfl-e"
   },
   "source": [
    "### **1.2 Inverted Yield Curve**\n",
    "\n",
    "An inverted yield curve is a downward sloping curve that implies a recession is about to happen. An inverted yield curve means that people believe interest rates will be lower than they currently are, and we therefore expect the central banks to cut interest rates so as to encourage borrowing of more money by investors, consumers, and businesses. This in turn leads to economic growth."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4sTuqTbxg6fS",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "4sTuqTbxg6fS"
   },
   "source": [
    "### **1.3 Flat Yield Curve**\n",
    "\n",
    "We get a flat yield curve when an economy is shifting from one state to another. For example, when an expanding economy starts contracting we see that a yield curve that was initially normal begins to flatten due to people expecting an economic downturn and thus a drop in long-term interest rates. The opposite is also true."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "DOqOmmBEoy66",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "DOqOmmBEoy66"
   },
   "source": [
    "Now that we have a grasp of how useful yield curves are, in the subsequent sections, we are going to forecast yield curves using conventional machine learning algorithms and a deep learning algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "818cbea5",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "818cbea5"
   },
   "source": [
    "## **2. Forecasting Yield Curves**\n",
    "This case study is a time series problem whose foundation we studied in the Econometrics course. It is also a supervised machine learning problem since we have outputs that our model will be learning from. The predicted variables in this case will be multiple outputs. \n",
    "\n",
    "To solve this problem, we will follow an industry standard methodology: Cross-Industry Process for Data Mining (CRISP-DM) used for solving data science problems. \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Ef6mSAQloksv",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "Ef6mSAQloksv"
   },
   "source": [
    "With the exception of the deployment stage, which is left for curious students to practice on their own, the other steps will be demonstrated here.\n",
    "\n",
    "### **2.1 Problem Understanding**\n",
    "The focus of this study is to find and understand factors that affect movements of the yield curve. Among the variables we will use are the historical data of the yield curve, federal debt percentage that is held by investors, and the corporate spread. The dependent variable will be the 1-month, 5-year and 30-year tenure of the yield curve.\n",
    "\n",
    "We sourced our data from the Yahoo and FRED websites. In this problem, we will use polynomials of various degrees to forecast the yield curves.\n",
    "\n",
    "### **2.2 Data Understanding**\n",
    "We start by loading packages that we will use throughout this lesson as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c165aa8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "deletable": false,
    "id": "1c165aa8",
    "outputId": "90766883-e693-4821-f9b0-5ecc486c66b0"
   },
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "# Global Libraries\n",
    "# Disable the warnings\n",
    "import warnings\n",
    "\n",
    "# Time series Models\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pandas_datareader.data as web\n",
    "\n",
    "# Plotting\n",
    "import seaborn as sns\n",
    "\n",
    "# Libraries for Statistical Models\n",
    "import statsmodels.api as sm\n",
    "from matplotlib import pyplot\n",
    "from pandas.plotting import scatter_matrix\n",
    "\n",
    "# Regression ML\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Loss Function\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Modeling\n",
    "from sklearn.model_selection import (\n",
    "    GridSearchCV,\n",
    "    KFold,\n",
    "    cross_val_score,\n",
    "    train_test_split,\n",
    ")\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71a29112",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "71a29112"
   },
   "source": [
    "Next, we load the data using the pandas `datareader` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b427b148",
   "metadata": {
    "deletable": false,
    "id": "b427b148"
   },
   "outputs": [],
   "source": [
    "# downloading the data\n",
    "start = datetime(2007, 6, 30)\n",
    "end = datetime(2022, 6, 30)\n",
    "\n",
    "data = [\n",
    "    \"DGS1MO\",\n",
    "    \"DGS3MO\",\n",
    "    \"DGS1\",\n",
    "    \"DGS2\",\n",
    "    \"DGS5\",\n",
    "    \"DGS7\",\n",
    "    \"DGS10\",\n",
    "    \"DGS30\",\n",
    "    \"TREAST\",  # -- U.S. Treasury securities held by the Federal Reserve ( Millions of Dollars )\n",
    "    \"FYGFDPUN\",  # -- Federal Debt Held by the Public ( Millions of Dollars )\n",
    "    \"FDHBFIN\",  # -- Federal Debt Held by Foreign and International Investors ( Billions of Dollars )\n",
    "    \"GFDEBTN\",  # -- Federal Debt: Total Public Debt ( Millions of Dollars )\n",
    "    \"BAA10Y\",  # -- Baa Corporate Bond Yield Relative to Yield on 10-Year\n",
    "]\n",
    "data = web.DataReader(data, \"fred\", start, end).dropna(how=\"all\").ffill()\n",
    "data[\"FDHBFIN\"] = data[\"FDHBFIN\"] * 1000\n",
    "data[\"GOV_PCT\"] = data[\"TREAST\"] / data[\"GFDEBTN\"]\n",
    "data[\"HOM_PCT\"] = data[\"FYGFDPUN\"] / data[\"GFDEBTN\"]\n",
    "data[\"FOR_PCT\"] = data[\"FDHBFIN\"] / data[\"GFDEBTN\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3fd8a68",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "d3fd8a68"
   },
   "source": [
    "We then define independent and dependent variables as mentioned in the previous subsection, and we also make an assumption that trading only happens on weekdays. As such, we will calculate the lagged version of the variables using a 5 trading day lag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ddc75d5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 394
    },
    "deletable": false,
    "id": "7ddc75d5",
    "outputId": "2522e23c-40be-413f-b366-face24233637"
   },
   "outputs": [],
   "source": [
    "data.rename(\n",
    "    columns={\n",
    "        \"DGS1MO\": \"1m\",\n",
    "        \"DGS3MO\": \"3m\",\n",
    "        \"DGS1\": \"1y\",\n",
    "        \"DGS2\": \"2y\",\n",
    "        \"DGS5\": \"5y\",\n",
    "        \"DGS7\": \"7y\",\n",
    "        \"DGS10\": \"10y\",\n",
    "        \"DGS30\": \"30y\",\n",
    "    },\n",
    "    inplace=True,\n",
    ")\n",
    "return_period = 5\n",
    "\n",
    "Y = data.loc[:, [\"1m\", \"5y\", \"30y\"]].shift(-return_period)\n",
    "Y.columns = [col + \"_pred\" for col in Y.columns]\n",
    "\n",
    "X = data.loc[\n",
    "    :,\n",
    "    [\n",
    "        \"1m\",\n",
    "        \"3m\",\n",
    "        \"1y\",\n",
    "        \"2y\",\n",
    "        \"5y\",\n",
    "        \"7y\",\n",
    "        \"10y\",\n",
    "        \"30y\",\n",
    "        \"GOV_PCT\",\n",
    "        \"HOM_PCT\",\n",
    "        \"FOR_PCT\",\n",
    "        \"BAA10Y\",\n",
    "    ],\n",
    "]\n",
    "\n",
    "df = pd.concat([Y, X], axis=1).dropna().iloc[::return_period, :]\n",
    "Y = df.loc[:, Y.columns]\n",
    "X = df.loc[:, X.columns]\n",
    "\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2268ae56",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "2268ae56"
   },
   "source": [
    "### **2.3 Exploratory Data Analysis (EDA)**\n",
    "EDA allows us to understand the hidden structure of our dataset by visualizing trends, relationships, and patterns that would have escaped the human eye. With EDA, we can already start to draw conclusions from our data. Exploring data constitutes a crucial step in our data analysis. In this subsection, we will show graphical exploratory data analysis that involves taking data from the dataframe and representing it graphically. Students are required to study the graphs closely to understand what they mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4720403d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "deletable": false,
    "id": "4720403d",
    "outputId": "ee216f1d-9057-4bd5-a6da-d8eb2cfedc79"
   },
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "556d0c2f",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "556d0c2f"
   },
   "source": [
    "This data has 243 observations and 15 variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0dec3cd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 364
    },
    "deletable": false,
    "id": "a0dec3cd",
    "outputId": "97d767c5-0810-4567-b084-9ed30e7ba45d"
   },
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24fe8067",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "24fe8067"
   },
   "source": [
    "We now plot the predicted variables to observe their behavior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "339e5a91",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 298
    },
    "deletable": false,
    "id": "339e5a91",
    "outputId": "71aad1f3-6ff7-4109-f656-fa0b9fcc795d"
   },
   "outputs": [],
   "source": [
    "# print('\\033[1m' + 'Fig 5: Yield Curve Prediction' + '\\033[0m' )\n",
    "Y.plot(style=[\"-\", \"--\", \"*\"])\n",
    "pyplot.suptitle(\n",
    "    \"Fig. 5: Yield Curve Prediction\",\n",
    "    fontweight=\"bold\",\n",
    "    horizontalalignment=\"right\",\n",
    "    fontsize=15,\n",
    ")\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f24ff38",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "4f24ff38"
   },
   "source": [
    "Notice that in the beginning of 2017, deviations for the 1-month, 5-year, and 30-year rates were high but steadily reduced afterwards. As of 2022, the medium- and long-term rates, that is 5 years and 30 years, were approximately equal but very much deviated from the short-term rate. Therefore, these time series trends show non-stationary behavior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2ea1156",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "deletable": false,
    "id": "c2ea1156",
    "outputId": "f8a3c50f-257b-4899-82d8-8d48cb4694cf"
   },
   "outputs": [],
   "source": [
    "# Scatterplot Matrix\n",
    "pyplot.figure(figsize=(15, 15))\n",
    "scatter_matrix(df, figsize=(15, 16))\n",
    "pyplot.suptitle(\n",
    "    \"Fig. 6: Scatter Plot Matrix\",\n",
    "    fontweight=\"bold\",\n",
    "    horizontalalignment=\"right\",\n",
    "    fontsize=15,\n",
    ")\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc97ff99",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "dc97ff99"
   },
   "source": [
    "From the above scatter plots, it is evident that there exists a strong linear relationship between the predicted variables and other tenures in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "252a61d0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "deletable": false,
    "id": "252a61d0",
    "outputId": "37027799-0913-4066-b06d-3da17a42bb7d"
   },
   "outputs": [],
   "source": [
    "# correlation\n",
    "correlation = df.corr()\n",
    "pyplot.figure(figsize=(16, 16))\n",
    "pyplot.title(\"Correlation Matrix\")\n",
    "pyplot.suptitle(\n",
    "    \"Fig. 7: Correlation Plot\",\n",
    "    fontweight=\"bold\",\n",
    "    horizontalalignment=\"right\",\n",
    "    fontsize=15,\n",
    ")\n",
    "sns.heatmap(correlation, vmax=1, square=True, annot=True, cmap=\"cubehelix\")\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64830b01",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "64830b01"
   },
   "source": [
    "The correlation plot above can be interpreted in a similar manner as the scatter plot figure discussed earlier."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20bbc541",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "20bbc541"
   },
   "source": [
    "We now do an EDA on the predicted variables as a time series plot.\n",
    "\n",
    "First is the 1-month time series analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3feb351",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 531
    },
    "deletable": false,
    "id": "a3feb351",
    "outputId": "367e2b3b-2cdb-4ae3-c242-1ecc99803056"
   },
   "outputs": [],
   "source": [
    "temp_Y = df[\"1m_pred\"]\n",
    "res = sm.tsa.seasonal_decompose(temp_Y, period=52)\n",
    "fig = res.plot()\n",
    "fig.set_figheight(8)\n",
    "fig.set_figwidth(15)\n",
    "pyplot.suptitle(\n",
    "    \"Fig. 8: Time Series Trend Analysis for 1 month period\",\n",
    "    fontweight=\"bold\",\n",
    "    horizontalalignment=\"right\",\n",
    "    fontsize=15,\n",
    ")\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bd850ec",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "3bd850ec"
   },
   "source": [
    "Then, the 5-year analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c2de387",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 531
    },
    "deletable": false,
    "id": "7c2de387",
    "outputId": "d818bd4d-2c99-47ff-8be1-29a2a5d24dcb"
   },
   "outputs": [],
   "source": [
    "temp_Y = df[\"5y_pred\"]\n",
    "res = sm.tsa.seasonal_decompose(temp_Y, period=52)\n",
    "fig = res.plot()\n",
    "fig.set_figheight(8)\n",
    "fig.set_figwidth(15)\n",
    "pyplot.suptitle(\n",
    "    \"Fig. 9: Time Series Trend Analysis of the 5-Year predicted variable\",\n",
    "    fontweight=\"bold\",\n",
    "    horizontalalignment=\"right\",\n",
    "    fontsize=15,\n",
    ")\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b10f9a8",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "4b10f9a8"
   },
   "source": [
    "Finally, the 30-year variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b373246",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 531
    },
    "deletable": false,
    "id": "7b373246",
    "outputId": "1406892c-7e07-4594-875a-d421020d37ca"
   },
   "outputs": [],
   "source": [
    "temp_Y = df[\"30y_pred\"]\n",
    "res = sm.tsa.seasonal_decompose(temp_Y, period=52)\n",
    "fig = res.plot()\n",
    "fig.set_figheight(8)\n",
    "fig.set_figwidth(15)\n",
    "pyplot.suptitle(\n",
    "    \"Fig. 10: Time Series Trend Analysis of the 30-Year predicted variable\",\n",
    "    fontweight=\"bold\",\n",
    "    horizontalalignment=\"right\",\n",
    "    fontsize=15,\n",
    ")\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98f95034",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "98f95034"
   },
   "source": [
    "## **3. Data Preparation**\n",
    "\n",
    "The dataset in this exercise does not need much preprocessing, and therefore, we are going to use it as is. Note that data preparation involves transforming the data, for example, by scaling so that we remove bias when running machine learning algorithms on our datasets.\n",
    "\n",
    "## **4. Modeling**\n",
    "\n",
    "###  **4.1 Splitting the Dataset into Train and Test Samples**\n",
    "\n",
    "We will split the data into $80\\%$ for training (modeling) the dataset and $20\\%$ to validate our model. To evaluate our algorithms, we choose the mean squared error since this is a regression exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "968e0c44",
   "metadata": {
    "deletable": false,
    "id": "968e0c44"
   },
   "outputs": [],
   "source": [
    "# split out validation dataset for model validation\n",
    "test_size = 0.2\n",
    "\n",
    "seed = 42\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, Y, test_size=test_size, random_state=seed\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6cafd64",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "e6cafd64"
   },
   "source": [
    "We use cross-validation to validate the model while training on the limited data sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d127ee6b",
   "metadata": {
    "deletable": false,
    "id": "d127ee6b"
   },
   "outputs": [],
   "source": [
    "# test options for regression\n",
    "num_folds = 10\n",
    "scoring = \"neg_mean_squared_error\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c68ba1c4",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "c68ba1c4"
   },
   "source": [
    "### **4.2 Forecasting Yield Curves: Fitting High Order Polynomials**\n",
    "Linear regression assumes that there exists a linear relationship between the dependent and independent variables. To account for non-linearity in our dataset, we choose to employ polynomial regression by adding polynomial terms:\n",
    "$$y = w_1 x + w_2 x^2 + \\cdots + w_m x^m + b$$\n",
    "where $m$ is the degree of our polynomial.\n",
    "\n",
    "In our case study, we will compare the performance of 1-order, 2-order, and 3-order polynomial regressions. We use transformer `PoynomialFeatures` from scikit-learn to add quadratic terms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd7c72e1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "deletable": false,
    "id": "bd7c72e1",
    "outputId": "ae5f0e82-b3c6-4a4a-c699-18977495f22f"
   },
   "outputs": [],
   "source": [
    "lr = LinearRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "pred = lr.predict(X_test)\n",
    "\n",
    "MSE = mean_squared_error(y_test, pred)\n",
    "\n",
    "print(\"linear regression mean squared error:\", MSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfc97d5d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "deletable": false,
    "id": "cfc97d5d",
    "outputId": "552a21e1-094b-4f21-8bc6-7e28e2a1aa1d"
   },
   "outputs": [],
   "source": [
    "# Quadratic\n",
    "poly = PolynomialFeatures(degree=2)\n",
    "X_train2 = poly.fit_transform(X_train)\n",
    "X_test2 = poly.fit_transform(X_test)\n",
    "\n",
    "model = lr.fit(X_train2, y_train)\n",
    "print(\n",
    "    \"quadratic regression mean squared error:\",\n",
    "    mean_squared_error(y_test, model.predict(X_test2)),\n",
    ")\n",
    "\n",
    "# Cubic\n",
    "poly = PolynomialFeatures(degree=3)\n",
    "X_train3 = poly.fit_transform(X_train)\n",
    "X_test3 = poly.fit_transform(X_test)\n",
    "\n",
    "model = lr.fit(X_train3, y_train)\n",
    "print(\n",
    "    \"degree 3 polynomial regression mean squared error:\",\n",
    "    mean_squared_error(y_test, model.predict(X_test3)),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b61a58a0",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "b61a58a0"
   },
   "source": [
    "Clearly, linear regression outperforms higher-order polynomials in the prediction task, and we would therefore use cross-validation with it to compare our output with a deep learning algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21793305",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "21793305"
   },
   "source": [
    "### **4.3 Forecasting Yield Curves: Cross-Validation**\n",
    "In $k$-fold cross-validation, data is split randomly into $k$ folds and without replacement. We train our data into $k-1$ folds and validate the model on the remaining one fold also called a test fold. The method is repeated $k$-terms, meaning we will have $k$ results. $k$-fold cross-validation is typically used for tuning our model.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Edp87xOgtxm_",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "Edp87xOgtxm_"
   },
   "source": [
    "We estimate the average performance $E$ by $$E = \\frac{1}{k} \\sum_{i=1}^k E_i$$\n",
    "\n",
    "Cross-validation can be applied to any model, and we will therefore first discuss neural networks in the next subsection and apply cross-validation in our neural network algorithm to fine-tune its performance.\n",
    "\n",
    "### **4.4 Forecasting Yield Curves - Backpropagation**\n",
    "\n",
    "In the last lesson, we studied backpropagation in detail and we will put our skills to practice in this section. We will later apply an artificial neural network algorithm, (MLP), which is part of the machine learning library in `sklearn`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c46fda7c",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "c46fda7c"
   },
   "source": [
    "Before we proceed, let us familiarize ourselves with some common terminology in deep learning:\n",
    "- **Forward pass**: It is synonymous with forward propagation, that is, moving from the input layer to the output layer.\n",
    "- **Backward pass**: It is synonymous with backward propagation, that is, moving from the output layer to the input layer.\n",
    "- **Epoch**: It is the number of times our model trains the whole data, that is, one epoch is equivalent to one forward pass and one backward pass for the training data.\n",
    "- **Iterations**: Number of times we perform forward pass and backward pass.\n",
    "- **Batch size**: It is the subset of training data that we use in one forward pass and one backward pass.\n",
    "\n",
    "In our model, we will use a two-layered neural network where the input layer has twelve variables, that is, the predictor variables. The hidden layer has 20 nodes for purposes of demonstration, and the output layer has three nodes corresponding to the predicted variables. So we start by defining the number of nodes in each layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9dc6703",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 335
    },
    "deletable": false,
    "id": "b9dc6703",
    "outputId": "49943963-e71d-43ac-fd0d-4c146f36d096"
   },
   "outputs": [],
   "source": [
    "from nnv import NNV\n",
    "\n",
    "print(\"\\033[1m\" + \"Fig 12: A Two Layer Neural Network\" + \"\\033[0m\")\n",
    "layersList = [\n",
    "    {\"title\": \"inputs \\n + bias\", \"units\": 12, \"color\": \"darkBlue\"},\n",
    "    {\"title\": \"hidden layer\", \"units\": 20},\n",
    "    # {\"title\":\"$f(z)$\", \"units\": 1, \"edges_color\":\"red\", \"edges_width\":2},\n",
    "    {\"title\": \"output\", \"units\": 3, \"color\": \"darkBlue\"},\n",
    "]\n",
    "\n",
    "NNV(layersList).render(save_to_file=\"my_example.png\")\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "532b02ef",
   "metadata": {
    "deletable": false,
    "id": "532b02ef"
   },
   "outputs": [],
   "source": [
    "num_input = 12\n",
    "num_hidden = 20\n",
    "num_output = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aa5e267",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "5aa5e267"
   },
   "source": [
    "Next, we initialize values of weights and bias randomly. We start by initializing the input to hidden layer weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8d455db",
   "metadata": {
    "deletable": false,
    "id": "b8d455db"
   },
   "outputs": [],
   "source": [
    "W_x_h = np.random.randn(num_input, num_hidden)\n",
    "b_h = np.zeros((1, num_hidden))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7190746d",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "7190746d"
   },
   "source": [
    "Then, we initialize the hidden layer to output layer weights and bias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b774e5cf",
   "metadata": {
    "deletable": false,
    "id": "b774e5cf"
   },
   "outputs": [],
   "source": [
    "W_h_y = np.random.randn(num_hidden, num_output)\n",
    "b_y = np.zeros((1, num_output))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51de470e",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "51de470e"
   },
   "source": [
    "We can now define our activation function and its derivative, in this case, the sigmoid function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3dbc835",
   "metadata": {
    "deletable": false,
    "id": "e3dbc835"
   },
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "\n",
    "def sigmoid_derivative(z):\n",
    "    return np.exp(-z) / ((1 + np.exp(-z)) ** 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18c0916d",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "18c0916d"
   },
   "source": [
    "As in the previous section, we then write  forward propagation and backward propagation functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d5f0b3e",
   "metadata": {
    "deletable": false,
    "id": "5d5f0b3e"
   },
   "outputs": [],
   "source": [
    "def forward_prop(X, W_x_h, W_h_y):\n",
    "    z_1 = np.dot(X, W_x_h) + b_h\n",
    "    a_1 = sigmoid(z_1)\n",
    "    z_2 = np.dot(a_1, W_h_y) + b_y\n",
    "    y_hat = sigmoid(z_2)\n",
    "\n",
    "    return z_1, a_1, z_2, y_hat\n",
    "\n",
    "\n",
    "def back_prop(y_hat, z_1, a_1, z_2):\n",
    "    delta2 = np.multiply(-(y_train - y_hat), sigmoid_derivative(z_2))\n",
    "    dJ_d_W_h_y = np.dot(a_1.T, delta2)\n",
    "    delta1 = np.dot(delta2, W_h_y.T) * sigmoid_derivative(z_1)\n",
    "    dJ_d_W_x_h = np.dot(X_train.T, delta1)\n",
    "\n",
    "    return dJ_d_W_x_h, dJ_d_W_h_y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e116205",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "2e116205"
   },
   "source": [
    "The cost function we use is the squared error as shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a40164d4",
   "metadata": {
    "deletable": false,
    "id": "a40164d4"
   },
   "outputs": [],
   "source": [
    "def cost_function(y, y_pred):\n",
    "    return 0.5 * np.sum((y - y_pred) ** 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec163cdb",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "ec163cdb"
   },
   "source": [
    "Before training our model, we set the learning rate and number of iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3bb7885",
   "metadata": {
    "deletable": false,
    "id": "e3bb7885"
   },
   "outputs": [],
   "source": [
    "alpha = 0.01\n",
    "num_iterations = 10000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41b34fbf",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "41b34fbf"
   },
   "source": [
    "We now train the neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcc89e3b",
   "metadata": {
    "deletable": false,
    "id": "dcc89e3b"
   },
   "outputs": [],
   "source": [
    "cost = []\n",
    "\n",
    "for i in range(num_iterations):\n",
    "    z_1, a_1, z_2, y_hat = forward_prop(X_train, W_x_h, W_h_y)\n",
    "    dJ_d_W_x_h, dJ_d_W_h_y = back_prop(y_hat, z_1, a_1, z_2)\n",
    "\n",
    "    # update weights\n",
    "    W_x_h = W_x_h - alpha * dJ_d_W_x_h\n",
    "    W_h_y = W_h_y - alpha * dJ_d_W_h_y\n",
    "\n",
    "    # compute cost\n",
    "    c = cost_function(y_train, y_hat)\n",
    "\n",
    "    cost.append(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beab0577",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "beab0577"
   },
   "source": [
    "The plot of the cost function is presented below:<span style='color: transparent; font-size:1%'>All rights reserved WQU WorldQuant University QQQQ</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d3318f3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 308
    },
    "deletable": false,
    "id": "2d3318f3",
    "outputId": "5f167d20-78a2-4b2b-a04a-bc64b1048969"
   },
   "outputs": [],
   "source": [
    "pyplot.grid()\n",
    "pyplot.plot(range(num_iterations), cost)\n",
    "\n",
    "pyplot.title(\"Cost Function\")\n",
    "pyplot.xlabel(\"Training Iterations\")\n",
    "pyplot.ylabel(\"Cost\")\n",
    "pyplot.suptitle(\n",
    "    \"Fig. 13: Cost Function Plot\",\n",
    "    fontweight=\"bold\",\n",
    "    horizontalalignment=\"right\",\n",
    "    fontsize=15,\n",
    ")\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a33721d4",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "a33721d4"
   },
   "source": [
    "As compared to the regression models in the first subsection of this section, the neural network model performs poorly. We can always improve this performance by increasing the number of nodes in the hidden layer or increasing the number of hidden layers to allow for complex modeling of the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "769f44e7",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "769f44e7"
   },
   "source": [
    "Now that we have a clear understanding of how neural networks work, let's implement a neural network algorithm called **Multilayer Perceptron** to predict yield curves."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c18bdc53",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "c18bdc53"
   },
   "source": [
    "We will use Multilayer Perceptron (MLP) as an example of a deep neural network that is fully connected."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20936a06",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "20936a06"
   },
   "source": [
    "As discussed above, an MLP algorithm follows these steps:\n",
    "\n",
    "1. Given an input layer, training data is forward-propagated through a deep neural network to get an output.\n",
    "2. Then, calculate the loss to check whether it is at a minimum.\n",
    "3. The loss is backpropagated and the model updated.\n",
    "\n",
    "Finally, once we are satisfied with the output of the above three steps, we use forward propagation to get our final output.\n",
    "\n",
    "Below is a demonstration of the use of cross-validation and backpropagation in forecasting yield curves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50f14c2e",
   "metadata": {
    "deletable": false,
    "id": "50f14c2e"
   },
   "outputs": [],
   "source": [
    "# test options for regression\n",
    "num_folds = 10\n",
    "scoring = \"neg_mean_squared_error\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d45f510",
   "metadata": {
    "deletable": false,
    "id": "2d45f510"
   },
   "outputs": [],
   "source": [
    "# spot check the algorithms\n",
    "models = []\n",
    "\n",
    "# Linear Regression Algorithm\n",
    "models.append((\"LR\", LinearRegression()))\n",
    "\n",
    "# Deep Learning Algorithm\n",
    "models.append((\"MLP\", MLPRegressor()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7c7f56e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "deletable": false,
    "id": "d7c7f56e",
    "outputId": "facd583a-9ff8-4557-e07b-e339b2ad21e0"
   },
   "outputs": [],
   "source": [
    "kfold_results = []\n",
    "names = []\n",
    "validation_results = []\n",
    "train_results = []\n",
    "for name, model in models:\n",
    "    kfold = KFold(n_splits=num_folds)\n",
    "    # converted mean square error to positive. The lower the better\n",
    "    cv_results = -1 * cross_val_score(\n",
    "        model, X_train, y_train, cv=kfold, scoring=scoring\n",
    "    )\n",
    "    kfold_results.append(cv_results)\n",
    "    names.append(name)\n",
    "\n",
    "    # Finally we Train on the full period and test against validation\n",
    "    res = model.fit(X_train, y_train)\n",
    "    validation_result = np.mean(np.square(res.predict(X_test) - y_test))\n",
    "    validation_results.append(validation_result)\n",
    "    train_result = np.mean(np.square(res.predict(X_train) - y_train))\n",
    "    train_results.append(train_result)\n",
    "\n",
    "    msg = (\n",
    "        \"%s: \\nAverage CV error: %s \\nStd CV Error: (%s) \\nTraining Error:\\n%s \\nTest Error:\\n%s\"\n",
    "        % (\n",
    "            name,\n",
    "            str(cv_results.mean()),\n",
    "            str(cv_results.std()),\n",
    "            str(train_result),\n",
    "            str(validation_result),\n",
    "        )\n",
    "    )\n",
    "    print(msg)\n",
    "    print(\"----------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54d35a81",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "54d35a81"
   },
   "source": [
    "Now let's compare performance of the two algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d094ff57",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 554
    },
    "deletable": false,
    "id": "d094ff57",
    "outputId": "9a5deb4a-ad64-447d-83db-66363112145e"
   },
   "outputs": [],
   "source": [
    "# compare algorithms\n",
    "names = [\"Linear Regression\", \"Multilinear Perceptron\"]\n",
    "fig = pyplot.figure()\n",
    "# print('\\033[1m' + 'Fig 14: Box Plot Comparing Model Performance' + '\\033[0m' )\n",
    "fig.suptitle(\"Algorithm Comparison\")\n",
    "ax = fig.add_subplot(111)\n",
    "pyplot.boxplot(kfold_results)\n",
    "ax.set_xticklabels(names)\n",
    "fig.set_size_inches(15, 8)\n",
    "pyplot.ylabel(\"Model Errors\")\n",
    "pyplot.xlabel(\"Models\")\n",
    "pyplot.suptitle(\n",
    "    \"Fig. 14: Box Plot Comparing Model Performance\",\n",
    "    fontweight=\"bold\",\n",
    "    horizontalalignment=\"right\",\n",
    "    fontsize=15,\n",
    ")\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdc15362",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 554
    },
    "deletable": false,
    "id": "fdc15362",
    "outputId": "b12b6cd4-37b6-49a7-e126-2f1ffb975707"
   },
   "outputs": [],
   "source": [
    "# compare algorithms\n",
    "fig = pyplot.figure()\n",
    "\n",
    "ind = np.arange(len(names))  # the x locations for the groups\n",
    "width = 0.35  # the width of the bars\n",
    "\n",
    "fig.suptitle(\"Algorithm Comparison\")\n",
    "ax = fig.add_subplot(111)\n",
    "pyplot.bar(\n",
    "    ind - width / 2, [x.mean() for x in train_results], width=width, label=\"Train Error\"\n",
    ")\n",
    "pyplot.bar(\n",
    "    ind + width / 2,\n",
    "    [x.mean() for x in validation_results],\n",
    "    width=width,\n",
    "    label=\"Validation Error\",\n",
    ")\n",
    "fig.set_size_inches(15, 8)\n",
    "pyplot.legend()\n",
    "pyplot.ylabel(\"Error\")\n",
    "pyplot.xlabel(\"Models\")\n",
    "ax.set_xticks(ind)\n",
    "ax.set_xticklabels(names)\n",
    "pyplot.suptitle(\n",
    "    \"Fig. 15: Bar Plot Comparing Training and Validation Error\",\n",
    "    fontweight=\"bold\",\n",
    "    horizontalalignment=\"right\",\n",
    "    fontsize=15,\n",
    ")\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b4b3fed",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "0b4b3fed"
   },
   "source": [
    "The linear regression model has fewer errors compared to MLP despite its simplicity. To improve the performance of the MLP regressor, we seek the best parameters by use of grid search as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e34a637f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "deletable": false,
    "id": "e34a637f",
    "outputId": "48f8230b-62cf-4762-82b4-c1c2fb83afd6"
   },
   "outputs": [],
   "source": [
    "# Grid search : `MLPRegressor`\n",
    "\"\"\"\n",
    "hidden_layer_sizes : tuple, length = n_layers - 2, default (100,)\n",
    "    The ith element represents the number of neurons in the ith\n",
    "    hidden layer.\n",
    "\"\"\"\n",
    "param_grid = {\"hidden_layer_sizes\": [(20,), (50,), (20, 20), (20, 30, 20)]}\n",
    "model = MLPRegressor()\n",
    "kfold = KFold(n_splits=num_folds)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, scoring=scoring, cv=kfold)\n",
    "grid_result = grid.fit(X_train, y_train)\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_[\"mean_test_score\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86b321e2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "deletable": false,
    "id": "86b321e2",
    "outputId": "05594d54-8421-4e55-daf4-df47c58c5bef"
   },
   "outputs": [],
   "source": [
    "# prepare model\n",
    "model = MLPRegressor(hidden_layer_sizes=(20, 30, 20))\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "201862b4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "deletable": false,
    "id": "201862b4",
    "outputId": "a4813537-7be2-4cd5-97c3-b342943c37cb"
   },
   "outputs": [],
   "source": [
    "# estimate accuracy on validation set\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "predictions = model.predict(X_test)\n",
    "mse_MLP = mean_squared_error(y_test, predictions)\n",
    "r2_MLP = r2_score(y_test, predictions)\n",
    "\n",
    "# prepare model\n",
    "model_2 = LinearRegression()\n",
    "model_2.fit(X_train, y_train)\n",
    "predictions_2 = model_2.predict(X_test)\n",
    "\n",
    "mse_OLS = mean_squared_error(y_test, predictions_2)\n",
    "r2_OLS = r2_score(y_test, predictions_2)\n",
    "print(\"MSE Regression = %f, MSE MLP = %f\" % (mse_OLS, mse_MLP))\n",
    "print(\"R2 Regression = %f, R2 MLP = %f\" % (r2_OLS, r2_MLP))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7a73a58",
   "metadata": {
    "deletable": false,
    "id": "c7a73a58"
   },
   "outputs": [],
   "source": [
    "train_size = int(len(X) * (1 - test_size))\n",
    "X_train, X_test = X[0:train_size], X[train_size : len(X)]\n",
    "y_train, y_test = Y[0:train_size], Y[train_size : len(X)]\n",
    "\n",
    "modelMLP = MLPRegressor(hidden_layer_sizes=(50,))\n",
    "modelOLS = LinearRegression()\n",
    "model_MLP = modelMLP.fit(X_train, y_train)\n",
    "model_OLS = modelOLS.fit(X_train, y_train)\n",
    "\n",
    "Y_predMLP = pd.DataFrame(\n",
    "    model_MLP.predict(X_test), index=y_test.index, columns=y_test.columns\n",
    ")\n",
    "\n",
    "Y_predOLS = pd.DataFrame(\n",
    "    model_OLS.predict(X_test), index=y_test.index, columns=y_test.columns\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cba78f8",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "6cba78f8"
   },
   "source": [
    "Let's compare the two predictions below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "733e4b28",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 379
    },
    "deletable": false,
    "id": "733e4b28",
    "outputId": "8b70920a-9b00-49b1-9623-9f18934f858f"
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(\n",
    "    {\n",
    "        \"Actual : 1m\": y_test.loc[:, \"1m_pred\"],\n",
    "        \"Prediction MLP 1m\": Y_predMLP.loc[:, \"1m_pred\"],\n",
    "        \"Prediction OLS 1m\": Y_predOLS.loc[:, \"1m_pred\"],\n",
    "    }\n",
    ").plot(figsize=(10, 5))\n",
    "pyplot.title(\"1 month rate prediction\")\n",
    "pyplot.ylabel(\"Yield Rates\")\n",
    "pyplot.suptitle(\n",
    "    \"Fig. 16: 1 Month Rate Prediction\",\n",
    "    fontweight=\"bold\",\n",
    "    horizontalalignment=\"right\",\n",
    "    fontsize=15,\n",
    ")\n",
    "pyplot.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "z1gnI6dClkqX",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 379
    },
    "deletable": false,
    "id": "z1gnI6dClkqX",
    "outputId": "5f0a0568-cb58-4763-9e33-730381bda5dc"
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(\n",
    "    {\n",
    "        \"Actual : 5yr\": y_test.loc[:, \"5y_pred\"],\n",
    "        \"Prediction MLP 5yr\": Y_predMLP.loc[:, \"5y_pred\"],\n",
    "        \"Prediction OLS 5yr\": Y_predOLS.loc[:, \"5y_pred\"],\n",
    "    }\n",
    ").plot(figsize=(10, 5))\n",
    "pyplot.title(\"5 years rate prediction\")\n",
    "pyplot.ylabel(\"Yield Rates\")\n",
    "pyplot.suptitle(\n",
    "    \"Fig. 17: 5 Years Prediction\",\n",
    "    fontweight=\"bold\",\n",
    "    horizontalalignment=\"right\",\n",
    "    fontsize=15,\n",
    ")\n",
    "pyplot.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6w64zBCNlmwI",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 379
    },
    "deletable": false,
    "id": "6w64zBCNlmwI",
    "outputId": "b81eb992-6d4f-431c-9eb8-734fee5c8b92"
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(\n",
    "    {\n",
    "        \"Actual : 30yr\": y_test.loc[:, \"30y_pred\"],\n",
    "        \"Prediction MLP 30yr\": Y_predMLP.loc[:, \"30y_pred\"],\n",
    "        \"Prediction OLS 30yr\": Y_predOLS.loc[:, \"30y_pred\"],\n",
    "    }\n",
    ").plot(figsize=(10, 5))\n",
    "pyplot.title(\"30 years rate prediction\")\n",
    "pyplot.ylabel(\"Yield Rates\")\n",
    "pyplot.suptitle(\n",
    "    \"Fig. 18: 30 Year Prediction\",\n",
    "    fontweight=\"bold\",\n",
    "    horizontalalignment=\"right\",\n",
    "    fontsize=15,\n",
    ")\n",
    "pyplot.show"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1053cfd3",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "1053cfd3"
   },
   "source": [
    "From the charts above, the linear regression model seems to provide a better prediction of yield rates as compared to the ANN model. \n",
    "\n",
    "## **5. Conclusion**\n",
    "\n",
    "In this lesson, we have applied an ordinary linear regression and a deep learning model to forecast yield curve in all short, medium, and long terms. Although the linear regression model outperformed the MLP model in this exercise, there are a variety of problems in which a deep learning model will give us superior results, and it is therefore advisable to try out a couple of models before settling on one. We have also seen that we can always improve the performance of neural networks by performing a grid search to select optimal parameters.\n",
    "\n",
    "The output of the deep learning model can be improved by finding the right hyperparameters and increasing the layers of the model. In the next lesson, we will look at optimization algorithms in deep learning, the challenges they face, how they affect output of our models, and how to address these challenges."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "YMiQl8G2uGwQ",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "YMiQl8G2uGwQ"
   },
   "source": [
    "**References**\n",
    "\n",
    "1. Bernadell, Carlos, et al. \"Yield Curve Prediction for the Strategic Investor.\" European Central Bank, *Working Paper Series*, no. 472, 2005.\n",
    "2. Bluwstein, Kristina, et al. \"Credit Growth, the Yield Curve and Financial Crisis Prediction: Evidence from a Machine Learning Approach.\" (2021).\n",
    "3. Hyndman, Cody. \"Arbitrage-Free Yield Curve and Bond Price Forecasting by Deep Neural Networks.\" *YouTube*, uploaded by Fields Institute, 29 Sept. 2021.\n",
    "4. Arnold, Ludovic, et al. \"An Introduction to Deep Learning.\" European Symposium on Artificial Neural Networks (ESANN), 2011."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ab3f5c4",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "---\n",
    "Copyright 2023 WorldQuant University. This\n",
    "content is licensed solely for personal use. Redistribution or\n",
    "publication of this material is strictly prohibited.\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
