{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "QA4C2gVkQwuS"
   },
   "source": [
    "## MACHINE LEARNING IN FINANCE\n",
    "MODULE 1 | LESSON 3\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "VSfXpUJ5Q3K7",
    "tags": []
   },
   "source": [
    "# **SUPERVISED MODELS: CLASSIFICATION**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "HjMi9S5nZC0V"
   },
   "source": [
    "|  |  |\n",
    "|:---|:---|\n",
    "|**Reading Time** |  60 minutes |\n",
    "|**Prior Knowledge** | Linear regression, Hyperparameters  |\n",
    "|**Keywords** | logistic regression, confusion matrix  |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "8LHX4uu6PJ1-"
   },
   "source": [
    "*In the last two lessons, we explored the supervised linear regression model. In this lesson, we will turn our attention to classification methods.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "9cF5JU3FRIzS"
   },
   "source": [
    "## **1. Introduction to Classification Models**\n",
    "\n",
    "In Lesson 1, we mentioned that the most common supervised learning tasks are\n",
    "regression (predicting values) and classification (predicting classes). In the first two lessons, we explored a regression task, predicting stock returns, using linear regression, and using regularization methods. Now, we will turn our attention to classification methods.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "5f5ntbkVT50D"
   },
   "source": [
    "### **1.1 Time Series Momentum: Thresholds**\n",
    "\n",
    "Let's consider the return prediction problem we studied in Lesson 1. Instead of trying to predict the realization of returns, we are now only interested in predicting whether the market is going up or down. Thus, we are going to classify the market into categories of positive return and negative return.\n",
    "\n",
    "Next, as we did in previous lessons, we upload the necessary information to train and evaluate the prediction model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 851
    },
    "deletable": false,
    "executionInfo": {
     "elapsed": 18865,
     "status": "ok",
     "timestamp": 1667687990104,
     "user": {
      "displayName": "Greg Ciresi",
      "userId": "03909397029203160502"
     },
     "user_tz": 240
    },
    "id": "FNq76uz8qBnq",
    "outputId": "a748bc5a-3d7e-43d9-fc7b-0fc89aef103e"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import yfinance as yf\n",
    "\n",
    "# Getting historical market data from SPY (ETF) (SPY)\n",
    "df = yf.download(\"SPY\", start=\"2000-01-01\", end=\"2022-01-01\")\n",
    "\n",
    "df[\"Ret\"] = df[\"Adj Close\"].pct_change()\n",
    "\n",
    "name = \"Ret\"\n",
    "df[\"Ret10_i\"] = (\n",
    "    df[name].rolling(10).apply(lambda x: 100 * ((np.prod(1 + x)) ** (1 / 10) - 1))\n",
    ")\n",
    "df[\"Ret25_i\"] = (\n",
    "    df[name].rolling(25).apply(lambda x: 100 * ((np.prod(1 + x)) ** (1 / 25) - 1))\n",
    ")\n",
    "df[\"Ret60_i\"] = (\n",
    "    df[name].rolling(60).apply(lambda x: 100 * ((np.prod(1 + x)) ** (1 / 60) - 1))\n",
    ")\n",
    "df[\"Ret120_i\"] = (\n",
    "    df[name].rolling(120).apply(lambda x: 100 * ((np.prod(1 + x)) ** (1 / 120) - 1))\n",
    ")\n",
    "df[\"Ret240_i\"] = (\n",
    "    df[name].rolling(240).apply(lambda x: 100 * ((np.prod(1 + x)) ** (1 / 240) - 1))\n",
    ")\n",
    "\n",
    "del df[\"Open\"]\n",
    "del df[\"Close\"]\n",
    "del df[\"High\"]\n",
    "del df[\"Low\"]\n",
    "del df[\"Volume\"]\n",
    "del df[\"Adj Close\"]\n",
    "\n",
    "df = df.dropna()\n",
    "df.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 504
    },
    "deletable": false,
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1667687993173,
     "user": {
      "displayName": "Greg Ciresi",
      "userId": "03909397029203160502"
     },
     "user_tz": 240
    },
    "id": "YW5xtXYMqJOB",
    "outputId": "ba1849d2-5411-4537-f288-6a853b72cf3e"
   },
   "outputs": [],
   "source": [
    "df[\"Ret25\"] = df[\"Ret25_i\"].shift(-25)\n",
    "df = df.dropna()\n",
    "df.tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "lmRL9iwyYvJA"
   },
   "source": [
    "We now transform our previous continuous label $y$ into a $\\{-1,1\\}$ variable that indicates whether the market has gone, respectively, down or up over a 25-day interval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 394
    },
    "deletable": false,
    "executionInfo": {
     "elapsed": 261,
     "status": "ok",
     "timestamp": 1667687996437,
     "user": {
      "displayName": "Greg Ciresi",
      "userId": "03909397029203160502"
     },
     "user_tz": 240
    },
    "id": "wRemvw2Mwz88",
    "outputId": "5792c7ab-b168-40b5-8bed-42221c230ca2"
   },
   "outputs": [],
   "source": [
    "df[\"Output\"] = df[\"Ret25\"].apply(np.sign)\n",
    "del df[\"Ret25\"]\n",
    "df.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "deletable": false,
    "executionInfo": {
     "elapsed": 358,
     "status": "ok",
     "timestamp": 1667687998929,
     "user": {
      "displayName": "Greg Ciresi",
      "userId": "03909397029203160502"
     },
     "user_tz": 240
    },
    "id": "kmzyAyC612lu",
    "outputId": "3e6edbc4-fabf-466f-fcb2-1556b6f6e12c"
   },
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "T0aT--XTZaxW"
   },
   "source": [
    "Split the information into a training set and test set. Below, we display the times series of the label we want to predict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "deletable": false,
    "executionInfo": {
     "elapsed": 227,
     "status": "ok",
     "timestamp": 1667688001251,
     "user": {
      "displayName": "Greg Ciresi",
      "userId": "03909397029203160502"
     },
     "user_tz": 240
    },
    "id": "dYFC88XA0KeR",
    "outputId": "f41029c4-ccb6-4dfe-ecf7-fae236344229"
   },
   "outputs": [],
   "source": [
    "X, y = df.iloc[:, 0:-1], df.iloc[:, -1]\n",
    "print(X.shape, y.shape)\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=int(len(y) * 0.5), shuffle=False\n",
    ")\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 428
    },
    "deletable": false,
    "executionInfo": {
     "elapsed": 295,
     "status": "ok",
     "timestamp": 1667688002795,
     "user": {
      "displayName": "Greg Ciresi",
      "userId": "03909397029203160502"
     },
     "user_tz": 240
    },
    "id": "Ye1dLKIhDrp5",
    "outputId": "b5ab34d8-8a36-4907-e7cc-ba49fbf15127"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(15, 7))\n",
    "plt.plot(\n",
    "    df.index,\n",
    "    np.cumsum(y),\n",
    "    label=\"Cumulative ups (+1) and downs (-1) of SPY over 25 days\",\n",
    ")\n",
    "legend = plt.legend(loc=\"upper left\")\n",
    "# plt.ylim([-1.25,1.25])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "zuKsCqexYMdj"
   },
   "source": [
    "### **1.2 Scaling**\n",
    "\n",
    "One important step before training an ML model involves data pre-processing. We will cover several techniques in the last module, but here, we are going to introduce one of the most important steps: *feature scaling*. Machine Learning algorithms perform badly when the input features have very different scales, which tends to slow down and worsen the performance of the optimization algorithms. There are two common ways to get all attributes to have the same scale: min-max scaling and standardization.\n",
    "\n",
    "Min-max scaling (many people call this normalization) is quite simple: Values are shifted and rescaled so that they end up ranging from 0 to 1. We do this by subtracting the min value and dividing by the max minus the min. Scikit-Learn provides a transformer called `MinMaxScaler` for this. Formally, each feature $j$ if instance $i$, $x_j^{(i)}$, is transformed as:\n",
    "$$\n",
    "\\begin{align*}\n",
    "x_j^{(i)}\\leftarrow \\frac{x_j^{(i)} - min_j}{max_j - min_j}\n",
    "\\end{align*} \n",
    "$$\n",
    "where $min_j$ and $max_j$ denote, respectively, the minimum and maximum values of the $j$th feature.\n",
    "\n",
    "Standardization is quite different: First, it subtracts the mean value (so standardized values always have a zero mean), and then it divides by the variance so that the resulting distribution has a unit variance. Unlike min-max scaling, standardization does not bound values to a specific range, which may be a problem for some algorithms. Scikit-Learn provides a transformer called `StandardScaler` for standardization.\n",
    "\n",
    "Another form of feature pre-processing is referred to as *whitening*, in which the axis-system is rotated to create a new set of de-correlated features, each of which is scaled to unit variance. Typically, Principal Component Analysis (a method of Unsupervised ML) is used to achieve this goal.\n",
    "\n",
    "It is important to fit the scalers to the training data only, not to the full dataset (including the test set). Only then can you use them to transform the training set and the test set (and new data).\n",
    "\n",
    "The block of code below scales the observations in our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "id": "tSsUmoM1-pOg"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler_input = MinMaxScaler(feature_range=(-1, 1))\n",
    "scaler_input.fit(X_train)\n",
    "X_train = scaler_input.transform(X_train)\n",
    "X_test = scaler_input.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "Lwhr3RVHUCPS"
   },
   "source": [
    "## **2. Logistic Regression Model**\n",
    "\n",
    "Logistic Regression (also called Logit Regression) is commonly\n",
    "used to estimate the probability that an instance belongs to a particular class (e.g., what is the probability that the market will go up?). If the estimated probability is greater than 50%, then the model predicts that the instance belongs to that class (called the positive class, labeled \"1\"), or else it predicts that it does not (i.e., it belongs to the negative class, labeled \"0\"). This makes it a binary classifier.\n",
    "\n",
    "Suppose that we have a training sample with instances where the labels $y$ simply denote if the market has gone up $y=1$ or gone down $y=0$. Just like a linear regression model, a logistic regression model computes a weighted sum of the input features (plus a bias term), but instead of outputting the result directly like the Linear Regression model does, it outputs the logistic of this result:\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\widehat{p}^{(i)}=\\sigma\\left(x^{(i)}\\theta\\right)\n",
    "\\end{align*}\n",
    "$$\n",
    "where $\\sigma(.)$ is the sigmoid function defined as:\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\sigma(z)=\\frac{1}{1+\\exp(-z)}\n",
    "\\end{align*}\n",
    "$$\n",
    "Then, the model's prediction from the Logistic Regression is given by:\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\widehat{y}^{(i)}=\\begin{cases}\n",
    "                   0\\ \\text{if}\\ \\widehat{p}^{(i)}\\lt 0.5 \\\\\n",
    "                                1\\ \\text{if}\\ \\widehat{p}^{(i)}\\geq 0.5 \n",
    "                  \\end{cases}\n",
    "\\end{align*}\n",
    "$$\n",
    "Notice that the Logistic Regression then predicts 1 if $x^{(i)}\\theta$ is positive and 0 otherwise.\n",
    "\n",
    "### **2.1 Training and Cost Function**\n",
    "\n",
    "The objective of training is to set the parameter vector $\\theta$ so that the model estimates high probabilities for positive instances ($y^{(i)}$ = 1) and low probabilities for negative instances ($y^{(i)}$ = 0). This idea is captured by the following cost function:\n",
    "$$\n",
    "\\begin{align*}\n",
    "J(\\theta) = - \\frac{1}{m}\\sum_{i=1}^m \\left[y^{(i)}log\\left(\\widehat{p}^{(i)}\\right) + \\left(1-y^{(i)}\\right)log\\left(1 - \\widehat{p}^{(i)}\\right) \\right]\n",
    "\\end{align*}\n",
    "$$\n",
    "This cost function makes sense because $-log\\left(\\widehat{p}^{(i)}\\right)$ grows very large when $\\widehat{p}^{(i)}$ approaches 0, so the cost will be large if the model estimates a probability close to 0 for a $y^{(i)}$ = 1, and similarly for $y^{(i)}$ = 0 if the negative when $\\widehat{p}^{(i)}$ approaches 1. Indeed, in Econometrics, the previous function is nothing more than the log-likelihood function for a Logit model.\n",
    "\n",
    "While there is no closed form for the vector $\\theta$ that maximizes the cost function above, we know that the function is convex and, for instance, Gradient Descent is guaranteed to find the global minimum as long as the learning rate is small enough and we wait for enough time. Thus, if we opt to use the Gradient Descent algorithm (either Batch, Mini-batch, or Stochastic) we would use the following partial derivatives from the cost function:\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\frac{\\partial}{\\partial\\theta_j}J(\\theta) = -\\frac{1}{m}\\sum_{i=1}^m \\left[y^{(i)} - \\sigma\\left(x^{(i)}\\theta\\right) \\right]x_j^{(i)}\n",
    "\\end{align*}\n",
    "$$\n",
    "Just like in the linear regression, logistic regression can be regularized using the ridge and lasso penalties we described in Lesson 2. Scikit-Learn actually adds an $\\ell_2$ (Ridge) penalty by default."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "PxEqQtZBbqTH"
   },
   "source": [
    "Let's train our stock market prediction model using time series information with a Logistic Regression.\n",
    "\n",
    "*Note: If we were interested in playing with the regularization strength, we should include as parameter the input \"C\" in the class `logisticRegr` defined below, where \"C\" is an inverse of the regularization strength.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "deletable": false,
    "executionInfo": {
     "elapsed": 318,
     "status": "ok",
     "timestamp": 1667688009224,
     "user": {
      "displayName": "Greg Ciresi",
      "userId": "03909397029203160502"
     },
     "user_tz": 240
    },
    "id": "jeTkL8Tr0Dis",
    "outputId": "a9973b13-3a4e-46a7-aa89-8c0c3fb80dc9"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# all parameters not specified are set to their defaults\n",
    "logisticRegr = LogisticRegression()\n",
    "logisticRegr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "id": "jt3lMK9f0Sc5"
   },
   "outputs": [],
   "source": [
    "predictions = logisticRegr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "deletable": false,
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1667688011507,
     "user": {
      "displayName": "Greg Ciresi",
      "userId": "03909397029203160502"
     },
     "user_tz": 240
    },
    "id": "HuEAMfzC0YRQ",
    "outputId": "5e15bfd1-f868-4ab8-a336-26279c59baf8"
   },
   "outputs": [],
   "source": [
    "# Use score method to get accuracy of model\n",
    "score = logisticRegr.score(X_test, y_test)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "agkSi5HHd81V"
   },
   "source": [
    "The model is able to predict the actual outcome 72% of the time. It seems a quite considerable figure given the simplicity of the model, right? Below, we show that this figure can be quite misleading. \n",
    "\n",
    "Before describing in detail the performance measures of classifiers, we first describe a simple generalization of logistic regression to a multiclass setup.<span style='color: transparent; font-size:1%'>All rights reserved WQU WorldQuant University QQQQ</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "Xm2aDWZKaFtd"
   },
   "source": [
    "### **2.2 Softmax Regression**\n",
    "\n",
    "The logistic regression model generalizes to multiple classes, without having to train and combine multiple binary classifiers. This is called *Softmax Regression* or *Multinomial Logit Regression*. For instance, imagine that we want to add a new category to our return prediction model that captures small movements in the returns of the market, say in the [-.5%,+.5%] range. Thus, we can train a model that predicts the probability that the market return is \"high\" (>.5%), low (<-.5%), or \"intermediate\".\n",
    "\n",
    "The Softmax Regression model first computes a score for each instance $i$ and category $c$, $x^{(i)}\\theta^{(c)}$, and then estimates the probability of each class by using the softmax function. Notice that each category has a specific vector of parameters, $\\theta^{(c)}$, with dimension equal to the number of input features, plus a bias term. \n",
    "\n",
    "Then, if we have $C$ different categories, the estimated probability of category $c$ for instance $i$ is given the exponential of its score, normalized by the sum of the exponential of the scores across categories.\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\widehat{p}_c^{(i)}=Softmax_c\\left(x^{(i)},\\Theta\\right)=\\frac{exp\\left(x^{(i)}\\theta^{(c)}\\right)}{\\sum_{j=1}^C exp\\left(x^{(i)}\\theta^{(j)}\\right)}\n",
    "\\end{align*}\n",
    "$$\n",
    "where $\\Theta$ collects all the parameters of the model. The model prediction $\\widehat{y}^{(i)}$ will be the category with the highest score $x^{(i)}\\theta^{(c)}$.\n",
    "\n",
    "In analogy with the logistic regression, the cost function to train the parameters of the model can be defined as:\n",
    "$$\n",
    "\\begin{align*}\n",
    "J(\\Theta) = - \\frac{1}{m}\\sum_{i=1}^m\\sum_{c=1}^C y^{(i)}log\\left(\\widehat{p}_c^{(i)}\\right) \n",
    "\\end{align*}\n",
    "$$\n",
    "which is generally called the *cross-entropy* cost function. The corresponding elements of the gradient vector are:\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\frac{\\partial}{\\partial\\theta_k^{(c)}}J(\\Theta) = -\\frac{1}{m}\\sum_{i=1}^m \\left[y^{(i)} - Softmax_c\\left(x^{(i)},\\Theta\\right) \\right]x_k^{(i)}\n",
    "\\end{align*}\n",
    "$$\n",
    "From which we can use Gradient Descent optimization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "7kLGxTCeUiRD"
   },
   "source": [
    "## **3. Performance Measures in Classification**\n",
    "\n",
    "Evaluating a classifier is often significantly trickier than evaluating a regression model. One simple measure of performance may simply be the frequency with which the classifier is successful at classifying the labels in the test sample, i.e., its *accuracy*. However, this indicator may be misleading. In our stock market prediction model, we found a 72% success rate in predicting whether the stock market is going up or down. However, such predictive power may arise simply from the model predicting most of the time that the stock market is going up, which happens with roughly 72% probability. This is the actual case, as we are going to show below. \n",
    "\n",
    "Similarly, our classification model may target the prediction of relatively rare classes or events, say a 5% probability event or class. In those instances, even a terrible classifier may achieve high accuracy. For instance, if we always predict that the event is never happening we are going to reach by default a 95% accuracy. To overcome this and improve the selection of classifier models, there are many performance measures available that we outline below.\n",
    "\n",
    "### **3.1 Confusion Matrix**\n",
    "\n",
    "A much better way to evaluate the performance of a classifier is to look at the confusion matrix. The general idea is to count the number of times instances of category A are classified as category B. To compute the confusion matrix, you first need to have a set of predictions so they can be compared to the actual targets. Each row in a confusion matrix represents an actual class, while each column represents a predicted class. A perfect classifier would have only true positives and true negatives, so its confusion matrix would have nonzero values only on its main diagonal (top left to bottom right).\n",
    "\n",
    "In the case of a two-category classifier where 0s are the negative class and 1s are the positive class, we can represent the confusion matrix as:\n",
    "$$\n",
    "\\begin{align*}\n",
    "Confusion = \\pmatrix{True\\ Negatives & False\\ Positives \\\\\n",
    "                      False\\ Negatives & True\\ Positives }\n",
    "\\end{align*}\n",
    "$$\n",
    "Let's observe the confusion matrix we obtain from our classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 520
    },
    "deletable": false,
    "executionInfo": {
     "elapsed": 466,
     "status": "ok",
     "timestamp": 1667688015669,
     "user": {
      "displayName": "Greg Ciresi",
      "userId": "03909397029203160502"
     },
     "user_tz": 240
    },
    "id": "bB2q2R8b0d_y",
    "outputId": "84020f43-b559-44b1-f106-cd2f0b304dd5"
   },
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import metrics\n",
    "\n",
    "cm = metrics.confusion_matrix(y_test, predictions)\n",
    "plt.figure(figsize=(9, 9))\n",
    "sns.heatmap(cm, annot=True, fmt=\".3f\", linewidths=0.5, square=True, cmap=\"Blues_r\")\n",
    "plt.ylabel(\"Actual label\")\n",
    "plt.xlabel(\"Predicted label\")\n",
    "all_sample_title = \"Accuracy Score: {0}\".format(score)\n",
    "plt.title(all_sample_title, size=15);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "_vTLVxBYiMPQ"
   },
   "source": [
    "Indeed, the 72% success rate of the model comes from it predicting that the stock market is going up, which takes place with a probability that is close to that success rate. Thus, we can assess that our model is a poor classifier to predict the returns of the stock market."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "QY0BSFfmfAIB"
   },
   "source": [
    "## **3.2 Precision and Recall**\n",
    "The extent of the positive predictions can be obtained through the precision of the classifier:\n",
    "$$\n",
    "\\begin{align*}\n",
    "Precision = \\frac{TP}{TP + FP}\n",
    "\\end{align*}\n",
    "$$\n",
    "where $TP$ is the total number of true positives and $FP$ is the number of false positives. That is, the denominator contains the number of times that the classifier has predicted a 1, so precision captures the proportion of accurate predictions over all the 1s that have been predicted by the model. \n",
    "\n",
    "Precision is usually combined with another metric, recall:\n",
    "$$\n",
    "\\begin{align*}\n",
    "Recall = \\frac{TP}{TP + FN}\n",
    "\\end{align*}\n",
    "$$\n",
    "Recall captures the proportion of accurate predictions over all the 1s that appear in the sample.\n",
    "\n",
    "Precision and recall are usually combined in a single metric that is named $F_1$ score, a harmonic mean of both values that gives much more weight to low values. Thus, the $F_1$ score will only be high if both precision and recall are high:\n",
    "$$\n",
    "\\begin{align*}\n",
    "F_1 = 2\\frac{Precision \\times Recall}{Precision + Recall}\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "The $F_1$ score favors classifiers with similar precision and recall. Sometimes, we do not want that. For instance, if we develop a model to detect the probability of a large drop (crash) in the stock market, in which case the category is 1, we may be willing to sacrifice some accuracy, predict the crash when it does not take place, against some recall, do not predict the crash when the crash actually happens.\n",
    "\n",
    "Unfortunately, we cannot have classifiers with both high precision and high recall at the same time. To see this, notice that models like logistic regression return probabilities rather than discrete outputs. To determine which class the model is predicting, we set a threshold value on the predicted probabilities to distinguish between a positive and a negative class, such as 0 or 5 in the Logistic Regression above. Depending on the threshold value, the predicted class of some observations may change. If a classifier sets a high threshold to increase precision, it is going to increase the number of positive cases that are going to be predicted as negative, reducing recall. Otherwise, if a classifier sets a high bar to increase recall, it is going to be at the cost of predicting more negative cases as positives, reducing precision.\n",
    "\n",
    "### **3.3 ROC and AUC**\n",
    "\n",
    "The Receiver Operating Characteristic (ROC) curve is another common tool used with binary classifiers. The ROC plots the recall of a classifier against the *false positive rate*, the proportion of 0s that are classified as 1s. As in the precision-recall trade-off, when a classifier increases its recall, then it is going to generate more false positives. One way to compare classifiers is to use the Area Under the Curve (AUC), which gives us the area that lies below the ROC of a classifier. For a perfect classifier, the AUC is one. For a purely random classifier, the AUC is 0.5. \n",
    "\n",
    "What metric should we use to determine what is a good classifier? We should use the $F_1$ when we care more about the false positives or when the positive class is rare. \n",
    "\n",
    "The block of code below plots the ROC curve for our logistic regression model. To obtain this, the roc_curve() function computes the recall, or True Positive Rate, and the False Positive Rate in the test sample for various threshold values that determine the prediction of the model. Notice how the predictive ability of the model is *among the poorest of the poor*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "deletable": false,
    "executionInfo": {
     "elapsed": 223,
     "status": "ok",
     "timestamp": 1667688087454,
     "user": {
      "displayName": "Greg Ciresi",
      "userId": "03909397029203160502"
     },
     "user_tz": 240
    },
    "id": "PxFZUCB3_Yzc",
    "outputId": "11ece0a5-ec58-4f37-eb3e-ad6e72500b60"
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y_test, predictions)\n",
    "roc_auc = metrics.auc(fpr, tpr)\n",
    "display = metrics.RocCurveDisplay(\n",
    "    fpr=fpr, tpr=tpr, roc_auc=roc_auc, estimator_name=\"estimation\"\n",
    ")\n",
    "display.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "UKm-ZBPRUpHz"
   },
   "source": [
    "## **4. Conclusion**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "iAJvEQaDmA-f"
   },
   "source": [
    "With this, we finish the description of basic classification problems in Machine Learning in the context of logistic regression. In Lesson 4, we will develop an application for credit scoring.\n",
    "\n",
    "See you there!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "---\n",
    "Copyright 2023 WorldQuant University. This\n",
    "content is licensed solely for personal use. Redistribution or\n",
    "publication of this material is strictly prohibited.\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
